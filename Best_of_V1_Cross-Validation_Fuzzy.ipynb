{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier werden Zahlen berechnet und keine Namen\n",
    "Zahlenausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store the data\n",
    "import pandas as pd\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# To create plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To create interactive plots\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# To shift lists\n",
    "from collections import deque\n",
    "\n",
    "# To compute similarities between vectors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# To use recommender systems\n",
    "import surprise as sp\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# To create deep learning models\n",
    "from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# To create sparse matrices\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# To light fm\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# To stack sparse matrices\n",
    "from scipy.sparse import vstack\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Als NÃ¤chstes sollen alle Pfade mit variablen belegt werden, dass macht das austauschen einfacher.\n",
    "\n",
    "movie_tile_File = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/movie_titles.csv'\n",
    "movie_tile_File_new = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Movie_Titles_clear.gzip'\n",
    "combined_data_1 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_1.txt'\n",
    "combined_data_2 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_2.txt'\n",
    "combined_data_3 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_3.txt'\n",
    "combined_data_4 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_4.txt'\n",
    "new_Combined = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Combined_Data_All.gzip'\n",
    "netflix_rating_Combined = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/netflix_data.csv'\n",
    "parquet_combined_data = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/data_Comb.zip'\n",
    "\n",
    "\n",
    "# Read Parquet\n",
    "data = pd.read_parquet(new_Combined)\n",
    "Convert_dic_data= {'Cust_Id': 'int64', 'Rating': 'float32', 'Movie_Id': 'Int64'}\n",
    "data= data.astype(Convert_dic_data)\n",
    "del new_Combined, Convert_dic_data\n",
    "\n",
    "## Read Movie Data\n",
    "movie_titles = pd.read_csv(movie_tile_File,\n",
    "                           encoding = \"ISO-8859-1\",\n",
    "                           delimiter= '\\t',\n",
    "                           header = None,\n",
    "                           names = ['Target'])\n",
    "                           # Speicher alle Daten erst in eine Reihe, danach trennt er diese\n",
    "movie_titles[['Movie_Id', 'Year', 'Name']] = movie_titles['Target'].str.split(pat=\",\",n=2, expand=True)   \n",
    "movie_titles= movie_titles.drop(['Target', 'Year'], axis= 1)  \n",
    "Convert_dic= {'Movie_Id': 'int64', 'Name': 'str'}\n",
    "movie_titles = movie_titles.astype(Convert_dic)\n",
    "#movie_titles.astype({'Movie_Id': 'int64', 'Name': 'str'}).dtypes\n",
    "#movie_titles.rename(columns={'Id':'Movie_Id'}, inplace=True)\n",
    "#movie_titles = movie_titles.reset_index(drop=True)\n",
    "display(movie_titles)\n",
    "del movie_tile_File, Convert_dic \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data\n",
    "# Filter sparse movies\n",
    "min_movie_ratings = 1000\n",
    "filter_movies = (df['Movie_Id'].value_counts()>min_movie_ratings)\n",
    "filter_movies = filter_movies[filter_movies].index.tolist()\n",
    "\n",
    "# Filter sparse users\n",
    "min_user_ratings = 200\n",
    "filter_users = (df['Cust_Id'].value_counts()>min_user_ratings)\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "# Actual filtering\n",
    "df_filterd = df[(df['Movie_Id'].isin(filter_movies)) & (df['Cust_Id'].isin(filter_users))]\n",
    "del filter_movies, filter_users, min_movie_ratings, min_user_ratings\n",
    "\n",
    "\n",
    "print('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\n",
    "print('Shape User-Ratings filtered:\\t{}'.format(df_filterd.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapper from movie title to index\n",
    "# pivot and create movie-user matrix\n",
    "movie_user_mat = df_filterd.pivot(index='Movie_Id', columns='Cust_Id', values='Rating').fillna(0)\n",
    "\n",
    "# create mapper from movie title to index\n",
    "movie_to_idx = {\n",
    "    movie: i for i, movie in \n",
    "    enumerate(list(movie_titles.set_index('Movie_Id').loc[movie_user_mat.index].Name))\n",
    "}\n",
    "# transform matrix to scipy sparse matrix\n",
    "# movie_user_mat_sparse = csr_matrix(movie_user_mat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=120, n_jobs=-1)\n",
    "# fit\n",
    "model_knn.fit(movie_user_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_matching(mapper, fav_movie, verbose=True):\n",
    "    #https://www.kaggle.com/code/ibtesama/getting-started-with-a-movie-recommendation-system\n",
    "    #https://www.kaggle.com/code/razor08/knn-based-collaborative-filtering?scriptVersionId=81850169  Wo kommmt der Code her\n",
    "    \"\"\"\n",
    "    return the closest match via fuzzy ratio. If no match found, return None\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    mapper: dict, map movie title name to index of the movie in data\n",
    "\n",
    "    fav_movie: str, name of user input movie\n",
    "    \n",
    "    verbose: bool, print log if True\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    index of the closest match\n",
    "    \"\"\"\n",
    "    match_tuple = []\n",
    "    # get match\n",
    "    for title, idx in mapper.items():\n",
    "        ratio = fuzz.ratio(title.lower(), fav_movie.lower())\n",
    "        if ratio >= 60:\n",
    "            match_tuple.append((title, idx, ratio))\n",
    "    # sort\n",
    "    match_tuple = sorted(match_tuple, key=lambda x: x[2])[::-1]\n",
    "    if not match_tuple:\n",
    "        print('Oops! No match is found')\n",
    "        return\n",
    "    if verbose:\n",
    "        print('Found possible matches in our database: {0}\\n'.format([x[0] for x in match_tuple]))\n",
    "    return match_tuple[0][1]\n",
    "\n",
    "\n",
    "\n",
    "def make_recommendation(model_knn, data, mapper, fav_movie, n_recommendations):\n",
    "    # fit\n",
    "    model_knn.fit(data)\n",
    "    # get input movie index\n",
    "    print('You have input movie:', fav_movie)\n",
    "    idx = fuzzy_matching(mapper, fav_movie, verbose=True)\n",
    "    # inference\n",
    "    print('Recommendation system start to make inference')\n",
    "    print('......\\n')\n",
    "    distances, indices = model_knn.kneighbors(data[idx], n_neighbors=n_recommendations+1)\n",
    "    # get list of raw idx of recommendations\n",
    "    raw_recommends = \\\n",
    "        sorted(list(zip(indices.squeeze().tolist(), distances.squeeze().tolist())), key=lambda x: x[1])[:0:-1]\n",
    "    # get reverse mapper\n",
    "    reverse_mapper = {v: k for k, v in mapper.items()}\n",
    "    # print recommendations\n",
    "    print('Recommendations for {}:'.format(fav_movie))\n",
    "    for i, (idx, dist) in enumerate(raw_recommends):\n",
    "        print('{0}: {1}, with distance of {2}'.format(i+1, reverse_mapper[idx], dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_favorite = 'Haiku Tunnel'\n",
    "\n",
    "make_recommendation(\n",
    "    model_knn=model_knn,\n",
    "    data=movie_user_mat,\n",
    "    fav_movie=my_favorite,\n",
    "    mapper=movie_to_idx,\n",
    "    n_recommendations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1acf06c8fd8bc80800f08a72a7dc06ca6ff72dd3d390f63a44d70f4da57fac27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
