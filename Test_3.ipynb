{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://blog.jaysinha.me/train-your-first-knn-model-for-collaborative-filtering/\n",
    "\n",
    "\n",
    "# To store the data\n",
    "import pandas as pd\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# To create plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To create interactive plots\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# To shift lists\n",
    "from collections import deque\n",
    "\n",
    "# To compute similarities between vectors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# To use recommender systems\n",
    "import surprise as sp\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# To create deep learning models\n",
    "from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# To create sparse matrices\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# To light fm\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# To stack sparse matrices\n",
    "from scipy.sparse import vstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wenn Colabs benutzt wird, kann es damit verbunden werden\n",
    "\n",
    "movie_tile_File = '/content/drive/MyDrive/Programmieprojekt/movie_titles.csv'\n",
    "movie_tile_File_new = '/content/drive/MyDrive/Programmieprojekt/movie_titles_new.csv'\n",
    "combined_data_1 = '/content/drive/MyDrive/Programmieprojekt/combined_data_1.txt'\n",
    "combined_data_2 = '/content/drive/MyDrive/Programmieprojekt/combined_data_2.txt'\n",
    "combined_data_3 = '/content/drive/MyDrive/Programmieprojekt/combined_data_3.txt'\n",
    "combined_data_4 = '/content/drive/MyDrive/Programmieprojekt/combined_data_4.txt'\n",
    "new_Combined = '/content/drive/MyDrive/Programmieprojekt/Cobined_data_new_v1.csv'\n",
    "netflix_rating_Combined = '/content/drive/MyDrive/Programmieprojekt/netflix_data.csv'\n",
    "parquet_combined_data = '/content/drive/MyDrive/Programmieprojekt/data_Comb.zip'\n",
    "\n",
    "#Als NÃ¤chstes sollen alle Pfade mit variablen belegt werden, dass macht das austauschen einfacher.\n",
    "\n",
    "movie_tile_File = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/movie_titles.csv'\n",
    "movie_tile_File_new = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/movie_titles_new.csv'\n",
    "combined_data_1 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_1.txt'\n",
    "combined_data_2 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_2.txt'\n",
    "combined_data_3 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_3.txt'\n",
    "combined_data_4 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_4.txt'\n",
    "new_Combined = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Cobined_data_new_v1.csv'\n",
    "netflix_rating_Combined = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/netflix_data.csv'\n",
    "parquet_combined_data = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/data_Comb.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data into viables\n",
    "\n",
    "\n",
    "combined_data_1_raw = pd.read_csv(combined_data_1, header=None, names=['Cust_Id', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "combined_data_2_raw = pd.read_csv(combined_data_2, header=None, names=['Cust_Id', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "combined_data_3_raw = pd.read_csv(combined_data_3, header=None, names=['Cust_Id', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "combined_data_4_raw = pd.read_csv(combined_data_4, header=None, names=['Cust_Id', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "\n",
    "## Combined_DATA_1\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_1_raw[combined_data_1_raw['Rating'].isna()]['Cust_Id'].reset_index()  \n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_1_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_1_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_1 = pd.concat(user_data)\n",
    "del user_data, combined_data_1_raw, combined_data_1, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "# print('Shape User-Ratings:\\t{}'.format(df_1.shape))\n",
    "\n",
    "## Combined_DATA_2\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_2_raw[combined_data_2_raw['Rating'].isna()]['Cust_Id'].reset_index()  ##---> Nachvollziehen\n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_2_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_2_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_2 = pd.concat(user_data)\n",
    "del user_data, combined_data_2_raw, combined_data_2, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "# print('Shape User-Ratings:\\t{}'.format(df_2.shape))\n",
    "\n",
    "## Combined_DATA_3\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_3_raw[combined_data_3_raw['Rating'].isna()]['Cust_Id'].reset_index()  ##---> Nachvollziehen\n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_3_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_3_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_3 = pd.concat(user_data)\n",
    "del user_data, combined_data_3_raw, combined_data_3, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "# print('Shape User-Ratings:\\t{}'.format(df_3.shape))\n",
    "\n",
    "## Combined_DATA_4\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_4_raw[combined_data_4_raw['Rating'].isna()]['Cust_Id'].reset_index()  ##---> Nachvollziehen\n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_4_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_4_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_4 = pd.concat(user_data)\n",
    "del user_data, combined_data_4_raw, combined_data_4, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "print('Shape User-Ratings:\\t{}'.format(df_4.shape))\n",
    "\n",
    "#ZusammenfÃ¼gen der aller Daten in einer Variable\n",
    "data = [df_1, df_2,df_3,df_4]\n",
    "df = pd.concat(data)\n",
    "df = df.drop('Date', axis= 1)\n",
    "del df_1, df_2, df_3, df_4\n",
    "print(df.tail(5))\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.astype({'Cust_Id': 'int32'}).dtypes\n",
    "df.astype({'Rating': 'int32'}).dtypes\n",
    "df.astype({'Movie_Id': 'int32'}).dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for all movies\n",
    "from multiprocessing import dummy\n",
    "\n",
    "\n",
    "movie_titles = pd.read_csv(movie_tile_File, \n",
    "                           encoding = 'ISO-8859-1', \n",
    "                           engine = 'python',\n",
    "                           delimiter =',',\n",
    "                           header = None, \n",
    "                           on_bad_lines= 'skip', #Wird gebraucht um Fehlerhafte Title zu behen.\n",
    "                           \n",
    "                           names = ['Id', 'Year', 'Name'])\n",
    "                           \n",
    "\n",
    "print('Shape Movie-Titles:\\t{}'.format(movie_titles.shape))\n",
    "\n",
    "#Zwischenspeichern der Movies, um fehlerhafte Liste zu bearbeiten\n",
    "movie_titles.to_csv(movie_tile_File_new,encoding = 'ISO-8859-1',sep=';')\n",
    "\n",
    "movie_titles.rename(columns={'Id':'Movie_Id'}, inplace=True)\n",
    "display(movie_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.tail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter sparse movies\n",
    "\n",
    "min_movie_ratings = 100000\n",
    "filter_movies = (df['Movie_Id'].value_counts()>min_movie_ratings)\n",
    "filter_movies = filter_movies[filter_movies].index.tolist()\n",
    "\n",
    "# Filter sparse users\n",
    "min_user_ratings = 1000\n",
    "filter_users = (df['Cust_Id'].value_counts()>min_user_ratings)\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "\n",
    "# Actual filtering\n",
    "df_filterd = df[(df['Movie_Id'].isin(filter_movies)) & (df['Cust_Id'].isin(filter_users))]\n",
    "del filter_movies, filter_users, min_movie_ratings, min_user_ratings\n",
    "\"\"\"\n",
    "# Actual filtering\n",
    "df_filterd = df[(df['Movie_Id'].isin(filter_movies)) & (df['Cust_Id'].isin(filter_users))]\n",
    "del filter_movies, filter_users, min_movie_ratings, min_user_ratings\n",
    "\"\"\"\n",
    "\n",
    "print('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\n",
    "print('Shape User-Ratings filtered:\\t{}'.format(df_filterd.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_user_mat = df_filterd.pivot_table(index = [\"Movie_Id\"],columns = [\"Cust_Id\"],values = \"Rating\").fillna(0)\n",
    "movie_user_mat_sparse = csr_matrix(movie_user_mat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[3428, 4433, 10948, 16140, 16385] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jsbreite\\OneDrive - Jannis Breitenstein IT\\Hochschule_Studium\\5_Semester\\Programmierprojekt\\Codes\\Github\\Test_3.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m movie_user_mat \u001b[39m=\u001b[39m df_filterd\u001b[39m.\u001b[39mpivot_table(index \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mMovie_Id\u001b[39m\u001b[39m\"\u001b[39m],columns \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mCust_Id\u001b[39m\u001b[39m\"\u001b[39m],values \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRating\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mfillna(\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# create mapper from movie title to index\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m movie_to_idx \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     movie: i \u001b[39mfor\u001b[39;00m i, movie \u001b[39min\u001b[39;00m \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39menumerate\u001b[39m(\u001b[39mlist\u001b[39m(movie_titles\u001b[39m.\u001b[39;49mset_index(\u001b[39m'\u001b[39;49m\u001b[39mMovie_Id\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mloc[(movie_user_mat\u001b[39m.\u001b[39;49mindex \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)]\u001b[39m.\u001b[39mName)) \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Die Mappings kÃ¶nnten falsch sein, da 0=1 gemappt werden\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# transform matrix to scipy sparse matrix\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m movie_user_mat_sparse \u001b[39m=\u001b[39m csr_matrix(movie_user_mat\u001b[39m.\u001b[39mvalues)\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    964\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m    966\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m--> 967\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1189\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1191\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1193\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1132\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1133\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1324\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1325\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1327\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1329\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[3428, 4433, 10948, 16140, 16385] not in index'"
     ]
    }
   ],
   "source": [
    "# Pivot and create movie-user matrix\n",
    "movie_user_mat = df_filterd.pivot_table(index = [\"Movie_Id\"],columns = [\"Cust_Id\"],values = \"Rating\").fillna(0)\n",
    "\n",
    "# create mapper from movie title to index\n",
    "\"\"\"\n",
    "movie_to_idx = {\n",
    "    movie: i for i, movie in \n",
    "    enumerate(list(movie_titles.set_index('Movie_Id').loc[(movie_user_mat.index + 1)].Name)) \n",
    "}\n",
    "\"\"\"\n",
    "# Die Mappings kÃ¶nnten falsch sein, da 0=1 gemappt werden\n",
    "# transform matrix to scipy sparse matrix\n",
    "movie_user_mat_sparse = csr_matrix(movie_user_mat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine', n_jobs=-1, n_neighbors=20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "\n",
    "model_knn.fit(movie_user_mat_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendation(model_knn, data, mapper, fav_movie, n_recommendations):\n",
    "    \n",
    "    model_knn.fit(data)\n",
    "    \n",
    "    print('You have input movie:', fav_movie)\n",
    "    #the function below is a helper function defined to check presence of Movie Name\n",
    "    idx = fuzzy_matching(mapper, fav_movie, verbose=True)\n",
    "    \n",
    "    print('Recommendation system start to make inference')\n",
    "    print('......\\n')\n",
    "    distances, indices = model_knn.kneighbors(data[idx], n_neighbors=n_recommendations+1)\n",
    "    # get list of raw idx of recommendations\n",
    "    raw_recommends = \\\n",
    "        sorted(list(zip(indices.squeeze().tolist(), distances.squeeze().tolist())), key=lambda x: x[1])[:0:-1]\n",
    "    # get reverse mapper\n",
    "    reverse_mapper = {v: k for k, v in mapper.items()}\n",
    "    # print recommendations\n",
    "    print('Recommendations for {}:'.format(fav_movie))\n",
    "    for i, (idx, dist) in enumerate(raw_recommends):\n",
    "        print('{0}: {1}, with distance of {2}'.format(i+1, reverse_mapper[idx], dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://datascience.stackexchange.com/questions/52704/how-to-save-a-knn-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movie_to_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jsbreite\\OneDrive - Jannis Breitenstein IT\\Hochschule_Studium\\5_Semester\\Programmierprojekt\\Codes\\Github\\Test_3.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m my_favorite \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mShawshank Redemption\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m make_recommendation(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model_knn\u001b[39m=\u001b[39mmodel_knn,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     data\u001b[39m=\u001b[39mmovie_user_mat_sparse,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     fav_movie\u001b[39m=\u001b[39mmy_favorite,\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     mapper\u001b[39m=\u001b[39mmovie_to_idx,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Test_3.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     n_recommendations\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'movie_to_idx' is not defined"
     ]
    }
   ],
   "source": [
    "my_favorite = 'Shawshank Redemption'\n",
    "\n",
    "make_recommendation(\n",
    "    model_knn=model_knn,\n",
    "    data=movie_user_mat_sparse,\n",
    "    fav_movie=my_favorite,\n",
    "    mapper=movie_to_idx,\n",
    "    n_recommendations=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1acf06c8fd8bc80800f08a72a7dc06ca6ff72dd3d390f63a44d70f4da57fac27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
