{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"d7aa1b0ad6979877450f9cd89e1e37289b51cf6e"},"source":["# **The Age of Recommender Systems**"]},{"cell_type":"markdown","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"},"source":["The rapid growth of data collection has led to a new era of information. Data is being used to create more efficient systems and this is where Recommendation Systems come into play.  Recommendation Systems are a type of **information filtering systems** as they improve the quality of search results and provides items that are more relevant to the search item or are realted to the search history of the user.  \n"]},{"cell_type":"markdown","metadata":{"_uuid":"65dbae55f1e6e06c5fa7251f8ddae887d3fbf480"},"source":["They are used to predict the **rating** or **preference** that a user would give to an item. Almost every major tech company has applied them in some form or the other: Amazon uses it to suggest products to customers, YouTube uses it to decide which video to play next on autoplay, and Facebook uses it to recommend pages to like and people to follow. \n","Moreover,  companies like Netflix and Spotify  depend highly on the effectiveness of their recommendation engines for their business and sucees."]},{"cell_type":"markdown","metadata":{"_uuid":"af1e8d514096cde4abeae2d65a44cfdb01228d77"},"source":["![](https://i.kinja-img.com/gawker-media/image/upload/s--e3_2HgIC--/c_scale,f_auto,fl_progressive,q_80,w_800/1259003599478673704.jpg)"]},{"cell_type":"markdown","metadata":{"_uuid":"f34fc4dcfba717692c620e1fdfa502ee910c6365"},"source":["In this kernel we'll be building a baseline Movie Recommendation System using [TMDB 5000 Movie Dataset](https://www.kaggle.com/tmdb/tmdb-movie-metadata). For novices like me this kernel will pretty much serve as a foundation in recommendation systems and will provide you with something to start with. "]},{"cell_type":"markdown","metadata":{"_uuid":"1fa8fc3cb8348853bb51472b248134a59c24bf60"},"source":["**So let's go!**"]},{"cell_type":"markdown","metadata":{"_uuid":"f9a9405b7e81c1da449bd2e96c2849fb86caa614"},"source":["There are basically three types of recommender systems:-\n","\n","> *  **Demographic Filtering**- They offer generalized recommendations to every user, based on movie popularity and/or genre. The System recommends the same movies to users with similar demographic features. Since each user is different , this approach is considered to be too simple. The basic idea behind this system is that movies that are more popular and critically acclaimed will have a higher probability of being liked by the average audience.\n","\n"]},{"cell_type":"markdown","metadata":{"_uuid":"60a2df15abf82ba21918e3a42cb0ee46d22fa764"},"source":["> *  **Content Based Filtering**- They suggest similar items based on a particular item. This system uses item metadata, such as genre, director, description, actors, etc. for movies, to make these recommendations. The general idea behind these recommender systems is that if a person liked a particular item, he or she will also like an item that is similar to it."]},{"cell_type":"markdown","metadata":{"_uuid":"b7e719fcc502c59f098a51ae35e2ceb6d7cdfe4e"},"source":["> *  **Collaborative Filtering**- This system matches persons with similar interests and provides recommendations based on this matching. Collaborative filters do not require item metadata like its content-based counterparts."]},{"cell_type":"markdown","metadata":{"_uuid":"6b418588e3f9139f74cb3a9546f5dca49729579b"},"source":["Let's load the data now."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: surprise in c:\\users\\jsbreite\\anaconda3\\lib\\site-packages (0.1)\n","Requirement already satisfied: scikit-surprise in c:\\users\\jsbreite\\anaconda3\\lib\\site-packages (from surprise) (1.1.2)\n","Requirement already satisfied: joblib>=1.0.0 in c:\\users\\jsbreite\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.1.0)\n","Requirement already satisfied: scipy>=1.3.2 in c:\\users\\jsbreite\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.7.3)\n","Requirement already satisfied: numpy>=1.17.3 in c:\\users\\jsbreite\\anaconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.21.5)\n"]}],"source":["# Install  Packets\n","\n","import sys\n","\n","!{sys.executable} -m pip install surprise\n","\n","\n","#Only Once"]},{"cell_type":"code","execution_count":1,"metadata":{"_uuid":"c1fdd129c1cbab68ae3e6bf2062575f01f80b87c","trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input/tmdb-movie-metadata/tmdb_5000_credits.csv'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\jsbreite\\OneDrive - Jannis Breitenstein IT\\Hochschule_Studium\\5_Semester\\Programmierprojekt\\Codes\\Github\\Jannis_Recommendation_Hybrid.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Hybrid.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Hybrid.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Hybrid.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df1\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m../input/tmdb-movie-metadata/tmdb_5000_credits.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Hybrid.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df2\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../input/tmdb-movie-metadata/tmdb_5000_movies.csv\u001b[39m\u001b[39m'\u001b[39m)\n","File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n","File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n","File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n","File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/tmdb-movie-metadata/tmdb_5000_credits.csv'"]}],"source":["import pandas as pd \n","import numpy as np \n","df1=pd.read_csv('../input/tmdb-movie-metadata/tmdb_5000_credits.csv')\n","df2=pd.read_csv('../input/tmdb-movie-metadata/tmdb_5000_movies.csv')"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/html":["        <script type=\"text/javascript\">\n","        window.PlotlyConfig = {MathJaxConfig: 'local'};\n","        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n","        if (typeof require !== 'undefined') {\n","        require.undef(\"plotly\");\n","        requirejs.config({\n","            paths: {\n","                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n","            }\n","        });\n","        require(['plotly'], function(Plotly) {\n","            window._Plotly = Plotly;\n","        });\n","        }\n","        </script>\n","        "]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning:\n","\n","LightFM was compiled without OpenMP support. Only a single thread will be used.\n","\n"]}],"source":["# To store the data\n","import pandas as pd\n","\n","# To do linear algebra\n","import numpy as np\n","\n","# To create plots\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# To create interactive plots\n","from plotly.offline import init_notebook_mode, plot, iplot\n","import plotly.graph_objs as go\n","init_notebook_mode(connected=True)\n","\n","# To shift lists\n","from collections import deque\n","\n","# To compute similarities between vectors\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# To use recommender systems\n","import surprise as sp\n","from surprise.model_selection import cross_validate\n","\n","# To create deep learning models\n","from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n","from keras.models import Model\n","\n","# To create sparse matrices\n","from scipy.sparse import coo_matrix\n","\n","# To light fm\n","from lightfm import LightFM\n","from lightfm.evaluation import precision_at_k\n","\n","# To stack sparse matrices\n","from scipy.sparse import vstack\n","from scipy.sparse import csr_matrix\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"ename":"ImportError","evalue":"cannot import name 'valuate' from 'surprise' (c:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\surprise\\__init__.py)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32mc:\\Users\\jsbreite\\OneDrive - Jannis Breitenstein IT\\Hochschule_Studium\\5_Semester\\Programmierprojekt\\Codes\\Github\\Jannis_Recommendation_Hybrid.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Hybrid.ipynb#Y143sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msurprise\u001b[39;00m \u001b[39mimport\u001b[39;00m SVD\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Hybrid.ipynb#Y143sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msurprise\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Hybrid.ipynb#Y143sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msurprise\u001b[39;00m \u001b[39mimport\u001b[39;00m valuate\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Hybrid.ipynb#Y143sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msurprise\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_validate\n","\u001b[1;31mImportError\u001b[0m: cannot import name 'valuate' from 'surprise' (c:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\surprise\\__init__.py)"]}],"source":["from surprise import SVD\n","from surprise import Dataset\n","from surprise import valuate\n","\n","from surprise.model_selection import cross_validate"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#Als Nächstes sollen alle Pfade mit variablen belegt werden, dass macht das austauschen einfacher.\n","\n","movie_tile_File = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/movie_titles.csv'\n","movie_tile_File_new = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/movie_titles_new.csv'\n","combined_data_1 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_1.txt'\n","combined_data_2 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_2.txt'\n","combined_data_3 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_3.txt'\n","combined_data_4 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_4.txt'\n","new_Combined = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Cobined_data_new_v1.csv'\n","netflix_rating_Combined = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/netflix_data.csv'\n","parquet_combined_data = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/data_Comb.zip'"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["#Load Data into viables\n","\n","combined_data_1_raw = pd.read_csv(combined_data_1, header=None, names=['Cust_Id', 'Rating'], usecols=[0, 1])\n","combined_data_2_raw = pd.read_csv(combined_data_2, header=None, names=['Cust_Id', 'Rating'], usecols=[0, 1])\n","combined_data_3_raw = pd.read_csv(combined_data_3, header=None, names=['Cust_Id', 'Rating'], usecols=[0, 1])\n","combined_data_4_raw = pd.read_csv(combined_data_4, header=None, names=['Cust_Id', 'Rating'], usecols=[0, 1])"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape User-Ratings:\t(26847523, 3)\n","          Cust_Id  Rating  Movie_Id\n","26851921  1790158     4.0     17770\n","26851922  1608708     3.0     17770\n","26851923   234275     1.0     17770\n","26851924   255278     4.0     17770\n","26851925   453585     2.0     17770\n","   Cust_Id  Rating  Movie_Id\n","1  1488844     3.0         1\n","2   822109     5.0         1\n","3   885013     4.0         1\n","4    30878     4.0         1\n","5   823519     3.0         1\n"]}],"source":["## Combined_DATA_1\n","# Find empty rows to slice dataframe for each movie\n","tmp_movies = combined_data_1_raw[combined_data_1_raw['Rating'].isna()]['Cust_Id'].reset_index()  \n","movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n","\n","# Shift the movie_indices by one to get start and endpoints of all movies\n","shifted_movie_indices = deque(movie_indices)\n","shifted_movie_indices.rotate(-1)\n","\n","\n","# Gather all dataframes\n","user_data = []\n","\n","# Iterate over all movies\n","for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n","    \n","    # Check if it is the last movie in the file\n","    if df_id_1<df_id_2:\n","        tmp_df = combined_data_1_raw.loc[df_id_1+1:df_id_2-1].copy()\n","    else:\n","        tmp_df = combined_data_1_raw.loc[df_id_1+1:].copy()\n","        \n","    # Create movie_id column\n","    tmp_df['Movie_Id'] = movie_id\n","    \n","    # Append dataframe to list\n","    user_data.append(tmp_df)\n","\n","# Combine all dataframes\n","df_1 = pd.concat(user_data)\n","del user_data, combined_data_1_raw, combined_data_1, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n","# print('Shape User-Ratings:\\t{}'.format(df_1.shape))\n","\n","## Combined_DATA_2\n","# Find empty rows to slice dataframe for each movie\n","tmp_movies = combined_data_2_raw[combined_data_2_raw['Rating'].isna()]['Cust_Id'].reset_index()  ##---> Nachvollziehen\n","movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n","\n","# Shift the movie_indices by one to get start and endpoints of all movies\n","shifted_movie_indices = deque(movie_indices)\n","shifted_movie_indices.rotate(-1)\n","\n","\n","# Gather all dataframes\n","user_data = []\n","\n","# Iterate over all movies\n","for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n","    \n","    # Check if it is the last movie in the file\n","    if df_id_1<df_id_2:\n","        tmp_df = combined_data_2_raw.loc[df_id_1+1:df_id_2-1].copy()\n","    else:\n","        tmp_df = combined_data_2_raw.loc[df_id_1+1:].copy()\n","        \n","    # Create movie_id column\n","    tmp_df['Movie_Id'] = movie_id\n","    \n","    # Append dataframe to list\n","    user_data.append(tmp_df)\n","\n","# Combine all dataframes\n","df_2 = pd.concat(user_data)\n","del user_data, combined_data_2_raw, combined_data_2, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n","# print('Shape User-Ratings:\\t{}'.format(df_2.shape))\n","\n","## Combined_DATA_3\n","# Find empty rows to slice dataframe for each movie\n","tmp_movies = combined_data_3_raw[combined_data_3_raw['Rating'].isna()]['Cust_Id'].reset_index()  ##---> Nachvollziehen\n","movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n","\n","# Shift the movie_indices by one to get start and endpoints of all movies\n","shifted_movie_indices = deque(movie_indices)\n","shifted_movie_indices.rotate(-1)\n","\n","\n","# Gather all dataframes\n","user_data = []\n","\n","# Iterate over all movies\n","for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n","    \n","    # Check if it is the last movie in the file\n","    if df_id_1<df_id_2:\n","        tmp_df = combined_data_3_raw.loc[df_id_1+1:df_id_2-1].copy()\n","    else:\n","        tmp_df = combined_data_3_raw.loc[df_id_1+1:].copy()\n","        \n","    # Create movie_id column\n","    tmp_df['Movie_Id'] = movie_id\n","    \n","    # Append dataframe to list\n","    user_data.append(tmp_df)\n","\n","# Combine all dataframes\n","df_3 = pd.concat(user_data)\n","del user_data, combined_data_3_raw, combined_data_3, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n","# print('Shape User-Ratings:\\t{}'.format(df_3.shape))\n","\n","## Combined_DATA_4\n","# Find empty rows to slice dataframe for each movie\n","tmp_movies = combined_data_4_raw[combined_data_4_raw['Rating'].isna()]['Cust_Id'].reset_index()  ##---> Nachvollziehen\n","movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n","\n","# Shift the movie_indices by one to get start and endpoints of all movies\n","shifted_movie_indices = deque(movie_indices)\n","shifted_movie_indices.rotate(-1)\n","\n","\n","# Gather all dataframes\n","user_data = []\n","\n","# Iterate over all movies\n","for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n","    \n","    # Check if it is the last movie in the file\n","    if df_id_1<df_id_2:\n","        tmp_df = combined_data_4_raw.loc[df_id_1+1:df_id_2-1].copy()\n","    else:\n","        tmp_df = combined_data_4_raw.loc[df_id_1+1:].copy()\n","        \n","    # Create movie_id column\n","    tmp_df['Movie_Id'] = movie_id\n","    \n","    # Append dataframe to list\n","    user_data.append(tmp_df)\n","\n","# Combine all dataframes\n","df_4 = pd.concat(user_data)\n","del user_data, combined_data_4_raw, combined_data_4, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n","print('Shape User-Ratings:\\t{}'.format(df_4.shape))\n","\n","#Zusammenfügen der aller Daten in einer Variable\n","data = [df_1, df_2,df_3,df_4]\n","df = pd.concat(data)\n","del df_1, df_2, df_3, df_4\n","print(df.tail(5))\n","print(df.head(5))"]},{"cell_type":"markdown","metadata":{"_uuid":"71b15b5c090694303fa5e8d67b8bf394e07f45d6"},"source":["# **Collaborative Filtering**\n","\n","Our content based engine suffers from some severe limitations. It is only capable of suggesting movies which are close to a certain movie. That is, it is not capable of capturing tastes and providing recommendations across genres.\n","\n","Also, the engine that we built is not really personal in that it doesn't capture the personal tastes and biases of a user. Anyone querying our engine for recommendations based on a movie will receive the same recommendations for that movie, regardless of who she/he is.\n","\n","Therefore, in this section, we will use a technique called Collaborative Filtering to make recommendations to Movie Watchers.\n","It is basically of two types:-\n","\n","*  **User based filtering**-  These systems recommend products to a user that similar users have liked. For measuring the similarity between two users we can either use pearson correlation or cosine similarity.\n","This filtering technique can be illustrated with an example. In the following matrixes, each row represents a user, while the columns correspond to different movies except the last one which records the similarity between that user and the target user. Each cell represents the rating that the user gives to that movie. Assume user E is the target.\n","![](https://cdn-images-1.medium.com/max/1000/1*9NBFo4AUQABKfoUOpE3F8Q.png)\n","\n","Since user A and F do not share any movie ratings in common with user E, their similarities with user E are not defined in Pearson Correlation. Therefore, we only need to consider user B, C, and D. Based on Pearson Correlation, we can compute the following similarity.\n","![](https://cdn-images-1.medium.com/max/1000/1*jZIMJzKM1hKTFftHfcSxRw.png)\n","\n","From the above table we can see that user D is very different from user E as the Pearson Correlation between them is negative. He rated Me Before You higher than his rating average, while user E did the opposite. Now, we can start to fill in the blank for the movies that user E has not rated based on other users.\n","![](https://cdn-images-1.medium.com/max/1000/1*9TC6BrfxYttJwiATFAIFBg.png)\n","\n","Although computing user-based CF is very simple, it suffers from several problems. One main issue is that users’ preference can change over time. It indicates that precomputing the matrix based on their neighboring users may lead to bad performance. To tackle this problem, we can apply item-based CF.\n","\n","* **Item Based Collaborative Filtering** - Instead of measuring the similarity between users, the item-based CF recommends items based on their similarity with the items that the target user rated. Likewise, the similarity can be computed with Pearson Correlation or Cosine Similarity. The major difference is that, with item-based collaborative filtering, we fill in the blank vertically, as oppose to the horizontal manner that user-based CF does. The following table shows how to do so for the movie Me Before You.\n","![](https://cdn-images-1.medium.com/max/1000/1*LqFnWb-cm92HoMYBL840Ew.png)\n","\n","It successfully avoids the problem posed by dynamic user preference as item-based CF is more static. However, several problems remain for this method. First, the main issue is ***scalability***. The computation grows with both the customer and the product. The worst case complexity is O(mn) with m users and n items. In addition, ***sparsity*** is another concern. Take a look at the above table again. Although there is only one user that rated both Matrix and Titanic rated, the similarity between them is 1. In extreme cases, we can have millions of users and the similarity between two fairly different movies could be very high simply because they have similar rank for the only user who ranked them both.\n","\n"]},{"cell_type":"markdown","metadata":{"_uuid":"4307f75107f9c5e5f911d52a6f1dc5530990c75e"},"source":["### **Single Value Decomposition**\n","One way to handle the scalability and sparsity issue created by CF is to leverage a **latent factor model** to capture the similarity between users and items. Essentially, we want to turn the recommendation problem into an optimization problem. We can view it as how good we are in predicting the rating for items given a user. One common metric is Root Mean Square Error (RMSE). **The lower the RMSE, the better the performance**.\n","\n","Now talking about latent factor you might be wondering what is it ?It is a broad idea which describes a property or concept that a user or an item have. For instance, for music, latent factor can refer to the genre that the music belongs to. SVD decreases the dimension of the utility matrix by extracting its latent factors. Essentially, we map each user and each item into a latent space with dimension r. Therefore, it helps us better understand the relationship between users and items as they become directly comparable. The below figure illustrates this idea.\n","\n","![](https://cdn-images-1.medium.com/max/800/1*GUw90kG2ltTd2k_iv3Vo0Q.png)"]},{"cell_type":"markdown","metadata":{"_uuid":"defca8163cfc24a97bee620d6a3d501aa2ec95ae"},"source":["Now enough said , let's see how to implement this.\n","Since the dataset we used before did not have userId(which is necessary for collaborative filtering) let's load another dataset. We'll be using the [**Surprise** ](https://surprise.readthedocs.io/en/stable/index.html) library to implement SVD."]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape User-Ratings unfiltered:\t(100480507, 3)\n","Shape User-Ratings filtered:\t(63197769, 3)\n"]}],"source":["# Filter sparse movies\n","min_movie_ratings = 8000\n","filter_movies = (df['Movie_Id'].value_counts()>min_movie_ratings)\n","filter_movies = filter_movies[filter_movies].index.tolist()\n","\n","# Filter sparse users\n","min_user_ratings = 200\n","filter_users = (df['Cust_Id'].value_counts()>min_user_ratings)\n","filter_users = filter_users[filter_users].index.tolist()\n","\n","# Actual filtering\n","df_filterd = df[(df['Movie_Id'].isin(filter_movies)) & (df['Cust_Id'].isin(filter_users))]\n","del filter_movies, filter_users, min_movie_ratings, min_user_ratings\n","print('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\n","print('Shape User-Ratings filtered:\\t{}'.format(df_filterd.shape))"]},{"cell_type":"code","execution_count":2,"metadata":{"_uuid":"9a7faf48bf42293d18b29efac95e15010f6c900e","trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'df_filterd' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\jsbreite\\OneDrive - Jannis Breitenstein IT\\Hochschule_Studium\\5_Semester\\Programmierprojekt\\Codes\\Github\\Jannis_Recommendation_Hybrid.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Hybrid.ipynb#Y124sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msurprise\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_validate\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Hybrid.ipynb#Y124sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m reader \u001b[39m=\u001b[39m Reader()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Hybrid.ipynb#Y124sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m ratings \u001b[39m=\u001b[39m df_filterd\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Hybrid.ipynb#Y124sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m ratings\u001b[39m.\u001b[39mhead(\u001b[39m5\u001b[39m)\n","\u001b[1;31mNameError\u001b[0m: name 'df_filterd' is not defined"]}],"source":["import pandas as pd\n","from surprise import SVD, Reader\n","from surprise import Dataset\n","from surprise.model_selection import cross_validate\n","\n","reader = Reader()\n","ratings = df_filterd\n","\n","ratings.head(5)"]},{"cell_type":"markdown","metadata":{"_uuid":"f8a5cd5580510c27846a564bfa6d13f1a6dfa6de"},"source":["Note that in this dataset movies are rated on a scale of 5 unlike the earlier one."]},{"cell_type":"code","execution_count":24,"metadata":{"_uuid":"75166cecd9821bab4299605b66ea2a7787a4c3b7","trusted":true},"outputs":[],"source":["data = Dataset.load_from_df(ratings[['Cust_Id', 'Rating', 'Movie_Id']], reader)\n"]},{"cell_type":"code","execution_count":25,"metadata":{"_uuid":"17880aee6e7750afed98002593251010dcf5fb20","trusted":true},"outputs":[],"source":["svd = SVD()\n","\n","cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"]},{"cell_type":"markdown","metadata":{"_uuid":"81f6d5f460d4cbaaa43b6bb86a0abd9bce1a3134"},"source":["We get a mean Root Mean Sqaure Error of 0.89 approx which is more than good enough for our case. Let us now train on our dataset and arrive at predictions."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"58007ee500ce1735d173c247d188a5cd603b803c","trusted":true},"outputs":[],"source":["trainset = data.build_full_trainset()\n","svd.fit(trainset)"]},{"cell_type":"markdown","metadata":{"_uuid":"e130ef65d2c6a59823869d5b08c44e96e06f3b94"},"source":["Let us pick user with user Id 1  and check the ratings she/he has given."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"5a526fddacb2f7234e524e71224fdd1aecdd6ec0","trusted":true},"outputs":[],"source":["ratings[ratings['userId'] == 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"0cb981abe36b30f8f27b4c5dc1b1d0e090431651","trusted":true},"outputs":[],"source":["svd.predict(1, 302, 3)"]},{"cell_type":"markdown","metadata":{"_uuid":"50cf59d88c55c17de150e6a84a190e179bec2d33"},"source":["For movie with ID 302, we get an estimated prediction of **2.618**. One startling feature of this recommender system is that it doesn't care what the movie is (or what it contains). It works purely on the basis of an assigned movie ID and tries to predict ratings based on how the other users have predicted the movie."]},{"cell_type":"markdown","metadata":{"_uuid":"aece2ca6c5dcfcc8287562733f74a31fa115605c"},"source":["## **Conclusion** \n","We create recommenders using demographic , content- based and collaborative filtering. While demographic filtering is very elemantary and cannot be used practically, **Hybrid Systems** can take advantage of content-based and collaborative filtering as the two approaches are proved to be almost complimentary.\n","This model was very baseline and only provides a fundamental framework to start with.\n","\n","I would like to mention some excellent refereces that I learned from\n","1. [https://hackernoon.com/introduction-to-recommender-system-part-1-collaborative-filtering-singular-value-decomposition-44c9659c5e75](https://hackernoon.com/introduction-to-recommender-system-part-1-collaborative-filtering-singular-value-decomposition-44c9659c5e75)\n","2. [https://www.kaggle.com/rounakbanik/movie-recommender-systems](https://www.kaggle.com/rounakbanik/movie-recommender-systems)\n","3. [http://trouvus.com/wp-content/uploads/2016/03/A-hybrid-movie-recommender-system-based-on-neural-networks.pdf](http://trouvus.com/wp-content/uploads/2016/03/A-hybrid-movie-recommender-system-based-on-neural-networks.pdf)\n","\n","If you enjoyed reading the kernel , hit the upvote button !\n","Please leave the feedback or suggestions below. "]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"1acf06c8fd8bc80800f08a72a7dc06ca6ff72dd3d390f63a44d70f4da57fac27"}}},"nbformat":4,"nbformat_minor":4}
