{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install  Packets\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install lightfm\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install surprise\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install scikit-surprise \n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install google.colab\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install plotly\n",
    "!{sys.executable} -m pip install fastparquet\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install Pylance\n",
    "\n",
    "#Only Once\n",
    "## https://academy.rapidminer.com/learn/article/recommendation-engine-youre-going-to-love-this-movie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning:\n",
      "\n",
      "LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To store the data\n",
    "import pandas as pd\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# To create plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To create interactive plots\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# To shift lists\n",
    "from collections import deque\n",
    "\n",
    "# To compute similarities between vectors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# To use recommender systems\n",
    "import surprise as sp\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# To create deep learning models\n",
    "from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# To create sparse matrices\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# To light fm\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# To stack sparse matrices\n",
    "from scipy.sparse import vstack\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "794bdbd7ce4aae6b3a6f6c00fdfe2d77a25a2c21",
    "id": "not1IYciLTcD"
   },
   "source": [
    "The ratings per movie as well as the ratings per user both have nearly a perfect **exponential decay**. Only very few \n",
    "movies/users have many ratings. \n",
    "\n",
    "***\n",
    "## <a id=8>8. Filter Sparse Movies And Users</a>\n",
    "\n",
    "To reduce the dimensionality of the dataset I am filtering rarely rated movies and rarely rating users out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Als Nächstes sollen alle Pfade mit variablen belegt werden, dass macht das austauschen einfacher.\n",
    "\n",
    "movie_tile_File = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/movie_titles.csv'\n",
    "movie_tile_File_new = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/movie_titles_new.csv'\n",
    "combined_data_1 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_1.txt'\n",
    "combined_data_2 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_2.txt'\n",
    "combined_data_3 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_3.txt'\n",
    "combined_data_4 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_4.txt'\n",
    "new_Combined = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Cobined_data_new_v1.csv'\n",
    "netflix_rating_Combined = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/netflix_data.csv'\n",
    "parquet_combined_data = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/data_Comb.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data into viables\n",
    "\n",
    "combined_data_1_raw = pd.read_csv(combined_data_1, header=None, names=['Cust_Id', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "combined_data_2_raw = pd.read_csv(combined_data_2, header=None, names=['Cust_Id', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "combined_data_3_raw = pd.read_csv(combined_data_3, header=None, names=['Cust_Id', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "combined_data_4_raw = pd.read_csv(combined_data_4, header=None, names=['Cust_Id', 'Rating', 'Date'], usecols=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape User-Ratings:\t(26847523, 4)\n",
      "          Cust_Id  Rating        Date  Movie_Id\n",
      "26851921  1790158     4.0  2005-11-01     17770\n",
      "26851922  1608708     3.0  2005-07-19     17770\n",
      "26851923   234275     1.0  2004-08-07     17770\n",
      "26851924   255278     4.0  2004-05-28     17770\n",
      "26851925   453585     2.0  2005-03-10     17770\n",
      "   Cust_Id  Rating        Date  Movie_Id\n",
      "1  1488844     3.0  2005-09-06         1\n",
      "2   822109     5.0  2005-05-13         1\n",
      "3   885013     4.0  2005-10-19         1\n",
      "4    30878     4.0  2005-12-26         1\n",
      "5   823519     3.0  2004-05-03         1\n"
     ]
    }
   ],
   "source": [
    "## Combined_DATA_1\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_1_raw[combined_data_1_raw['Rating'].isna()]['Cust_Id'].reset_index()  \n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_1_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_1_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_1 = pd.concat(user_data)\n",
    "del user_data, combined_data_1_raw, combined_data_1, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "# print('Shape User-Ratings:\\t{}'.format(df_1.shape))\n",
    "\n",
    "## Combined_DATA_2\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_2_raw[combined_data_2_raw['Rating'].isna()]['Cust_Id'].reset_index()  ##---> Nachvollziehen\n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_2_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_2_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_2 = pd.concat(user_data)\n",
    "del user_data, combined_data_2_raw, combined_data_2, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "# print('Shape User-Ratings:\\t{}'.format(df_2.shape))\n",
    "\n",
    "## Combined_DATA_3\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_3_raw[combined_data_3_raw['Rating'].isna()]['Cust_Id'].reset_index()  ##---> Nachvollziehen\n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_3_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_3_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_3 = pd.concat(user_data)\n",
    "del user_data, combined_data_3_raw, combined_data_3, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "# print('Shape User-Ratings:\\t{}'.format(df_3.shape))\n",
    "\n",
    "## Combined_DATA_4\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_4_raw[combined_data_4_raw['Rating'].isna()]['Cust_Id'].reset_index()  ##---> Nachvollziehen\n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_4_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_4_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_4 = pd.concat(user_data)\n",
    "del user_data, combined_data_4_raw, combined_data_4, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "print('Shape User-Ratings:\\t{}'.format(df_4.shape))\n",
    "\n",
    "#Zusammenfügen der aller Daten in einer Variable\n",
    "data = [df_1, df_2,df_3,df_4]\n",
    "df = pd.concat(data)\n",
    "del df_1, df_2, df_3, df_4\n",
    "print(df.tail(5))\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratings per movie as well as the ratings per user both have nearly a perfect **exponential decay**. Only very few \n",
    "movies/users have many ratings. \n",
    "\n",
    "***\n",
    "## <a id=8>8. Filter Sparse Movies And Users</a>\n",
    "\n",
    "To reduce the dimensionality of the dataset I am filtering rarely rated movies and rarely rating users out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape User-Ratings unfiltered:\t(100480507, 4)\n",
      "Shape User-Ratings filtered:\t(60546559, 4)\n"
     ]
    }
   ],
   "source": [
    "# Filter sparse movies\n",
    "min_movie_ratings = 10000\n",
    "filter_movies = (df['Movie_Id'].value_counts()>min_movie_ratings)\n",
    "filter_movies = filter_movies[filter_movies].index.tolist()\n",
    "\n",
    "# Filter sparse users\n",
    "min_user_ratings = 300\n",
    "filter_users = (df['Cust_Id'].value_counts()>min_user_ratings)\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "# Actual filtering\n",
    "df_filterd = df[(df['Movie_Id'].isin(filter_movies)) & (df['Cust_Id'].isin(filter_users))]\n",
    "del filter_movies, filter_users, min_movie_ratings, min_user_ratings\n",
    "print('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\n",
    "print('Shape User-Ratings filtered:\\t{}'.format(df_filterd.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cust_Id  Rating        Date  Movie_Id\n",
      "1  1488844     3.0  2005-09-06         1\n",
      "3   885013     4.0  2005-10-19         1\n",
      "4    30878     4.0  2005-12-26         1\n",
      "5   823519     3.0  2004-05-03         1\n",
      "6   893988     3.0  2005-11-17         1\n"
     ]
    }
   ],
   "source": [
    "print(df_filterd.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.30 GiB for an array with shape (150245, 9284) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jsbreite\\OneDrive - Jannis Breitenstein IT\\Hochschule_Studium\\5_Semester\\Programmierprojekt\\Codes\\Github\\Jannis_Recommendation_Modell_Kompakt.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Modell_Kompakt.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m csr_matrix\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Modell_Kompakt.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# pivot ratings into movie features\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Modell_Kompakt.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_movie_features \u001b[39m=\u001b[39m df_filterd\u001b[39m.\u001b[39;49mpivot(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Modell_Kompakt.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     index\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mMovie_Id\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Modell_Kompakt.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     columns\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mCust_Id\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Modell_Kompakt.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     values\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mRating\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Modell_Kompakt.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\u001b[39m.\u001b[39;49mfillna(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Modell_Kompakt.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# convert dataframe of movie features to scipy sparse matrix\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Jannis_Recommendation_Modell_Kompakt.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m mat_movie_features \u001b[39m=\u001b[39m csr_matrix(df_movie_features\u001b[39m.\u001b[39mvalues)\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:5220\u001b[0m, in \u001b[0;36mDataFrame.fillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[0;32m   5209\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   5210\u001b[0m \u001b[39m@doc\u001b[39m(NDFrame\u001b[39m.\u001b[39mfillna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_shared_doc_kwargs)\n\u001b[0;32m   5211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfillna\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5218\u001b[0m     downcast\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   5219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 5220\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfillna(\n\u001b[0;32m   5221\u001b[0m         value\u001b[39m=\u001b[39;49mvalue,\n\u001b[0;32m   5222\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   5223\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5224\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5225\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit,\n\u001b[0;32m   5226\u001b[0m         downcast\u001b[39m=\u001b[39;49mdowncast,\n\u001b[0;32m   5227\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6496\u001b[0m, in \u001b[0;36mNDFrame.fillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[0;32m   6493\u001b[0m         new_data \u001b[39m=\u001b[39m result\n\u001b[0;32m   6494\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 6496\u001b[0m         new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mfillna(\n\u001b[0;32m   6497\u001b[0m             value\u001b[39m=\u001b[39;49mvalue, limit\u001b[39m=\u001b[39;49mlimit, inplace\u001b[39m=\u001b[39;49minplace, downcast\u001b[39m=\u001b[39;49mdowncast\n\u001b[0;32m   6498\u001b[0m         )\n\u001b[0;32m   6499\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, ABCDataFrame) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m   6501\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhere(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotna(), value)\u001b[39m.\u001b[39m_mgr\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.fillna\u001b[1;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfillna\u001b[39m(\u001b[39mself\u001b[39m: T, value, limit, inplace: \u001b[39mbool\u001b[39m, downcast) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m--> 414\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m    415\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mfillna\u001b[39;49m\u001b[39m\"\u001b[39;49m, value\u001b[39m=\u001b[39;49mvalue, limit\u001b[39m=\u001b[39;49mlimit, inplace\u001b[39m=\u001b[39;49minplace, downcast\u001b[39m=\u001b[39;49mdowncast\n\u001b[0;32m    416\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:304\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    303\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    305\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    306\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:472\u001b[0m, in \u001b[0;36mBlock.fillna\u001b[1;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_can_hold_element(value):\n\u001b[0;32m    471\u001b[0m     nb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m--> 472\u001b[0m     putmask_inplace(nb\u001b[39m.\u001b[39;49mvalues, mask, value)\n\u001b[0;32m    473\u001b[0m     \u001b[39mreturn\u001b[39;00m nb\u001b[39m.\u001b[39m_maybe_downcast([nb], downcast)\n\u001b[0;32m    475\u001b[0m \u001b[39mif\u001b[39;00m noop:\n\u001b[0;32m    476\u001b[0m     \u001b[39m# we can't process the value, but nothing to do\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\pandas\\core\\array_algos\\putmask.py:60\u001b[0m, in \u001b[0;36mputmask_inplace\u001b[1;34m(values, mask, value)\u001b[0m\n\u001b[0;32m     57\u001b[0m         values[mask] \u001b[39m=\u001b[39m value\n\u001b[0;32m     58\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# GH#37833 np.putmask is more performant than __setitem__\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     np\u001b[39m.\u001b[39;49mputmask(values, mask, value)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mputmask\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.30 GiB for an array with shape (150245, 9284) and data type bool"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "# pivot ratings into movie features\n",
    "df_movie_features = df_filterd.pivot(\n",
    "    index='Movie_Id',\n",
    "    columns='Cust_Id',\n",
    "    values='Rating'\n",
    ").fillna(0)\n",
    "# convert dataframe of movie features to scipy sparse matrix\n",
    "mat_movie_features = csr_matrix(df_movie_features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import gc\n",
    "import argparse\n",
    "\n",
    "# data science imports\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# utils import\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "class KnnRecommender:\n",
    "    \"\"\"\n",
    "    This is an item-based collaborative filtering recommender with\n",
    "    KNN implmented by sklearn\n",
    "    \"\"\"\n",
    "    def __init__(self, path_movies, path_ratings):\n",
    "        \"\"\"\n",
    "        Recommender requires path to data: movies data and ratings data\n",
    "        Parameters\n",
    "        ----------\n",
    "        path_movies: str, movies data file path\n",
    "        path_ratings: str, ratings data file path\n",
    "        \"\"\"\n",
    "        self.path_movies = path_movies\n",
    "        self.path_ratings = path_ratings\n",
    "        self.movie_rating_thres = 0\n",
    "        self.user_rating_thres = 0\n",
    "        self.model = NearestNeighbors()\n",
    "\n",
    "    def set_filter_params(self, movie_rating_thres, user_rating_thres):\n",
    "        \"\"\"\n",
    "        set rating frequency threshold to filter less-known movies and\n",
    "        less active users\n",
    "        Parameters\n",
    "        ----------\n",
    "        movie_rating_thres: int, minimum number of ratings received by users\n",
    "        user_rating_thres: int, minimum number of ratings a user gives\n",
    "        \"\"\"\n",
    "        self.movie_rating_thres = movie_rating_thres\n",
    "        self.user_rating_thres = user_rating_thres\n",
    "\n",
    "    def set_model_params(self, n_neighbors, algorithm, metric, n_jobs=None):\n",
    "        \"\"\"\n",
    "        set model params for sklearn.neighbors.NearestNeighbors\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_neighbors: int, optional (default = 5)\n",
    "        algorithm: {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional\n",
    "        metric: string or callable, default 'minkowski', or one of\n",
    "            ['cityblock', 'cosine', 'euclidean', 'l1', 'l2', 'manhattan']\n",
    "        n_jobs: int or None, optional (default=None)\n",
    "        \"\"\"\n",
    "        if n_jobs and (n_jobs > 1 or n_jobs == -1):\n",
    "            os.environ['JOBLIB_TEMP_FOLDER'] = '/tmp'\n",
    "        self.model.set_params(**{\n",
    "            'n_neighbors': n_neighbors,\n",
    "            'algorithm': algorithm,\n",
    "            'metric': metric,\n",
    "            'n_jobs': n_jobs})\n",
    "\n",
    "    def _prep_data(self):\n",
    "        \"\"\"\n",
    "        prepare data for recommender\n",
    "        1. movie-user scipy sparse matrix\n",
    "        2. hashmap of movie to row index in movie-user scipy sparse matrix\n",
    "        \"\"\"\n",
    "        # read data\n",
    "        df_movies = pd.read_csv(\n",
    "            os.path.join(self.path_movies),\n",
    "            usecols=['movieId', 'title'],\n",
    "            dtype={'movieId': 'int32', 'title': 'str'})\n",
    "        df_ratings = pd.read_csv(\n",
    "            os.path.join(self.path_ratings),\n",
    "            usecols=['userId', 'movieId', 'rating'],\n",
    "            dtype={'userId': 'int32', 'movieId': 'int32', 'rating': 'float32'})\n",
    "        # filter data\n",
    "        df_movies_cnt = pd.DataFrame(\n",
    "            df_ratings.groupby('movieId').size(),\n",
    "            columns=['count'])\n",
    "        popular_movies = list(set(df_movies_cnt.query('count >= @self.movie_rating_thres').index))  # noqa\n",
    "        movies_filter = df_ratings.movieId.isin(popular_movies).values\n",
    "\n",
    "        df_users_cnt = pd.DataFrame(\n",
    "            df_ratings.groupby('userId').size(),\n",
    "            columns=['count'])\n",
    "        active_users = list(set(df_users_cnt.query('count >= @self.user_rating_thres').index))  # noqa\n",
    "        users_filter = df_ratings.userId.isin(active_users).values\n",
    "\n",
    "        df_ratings_filtered = df_ratings[movies_filter & users_filter]\n",
    "\n",
    "        # pivot and create movie-user matrix\n",
    "        movie_user_mat = df_ratings_filtered.pivot(\n",
    "            index='movieId', columns='userId', values='rating').fillna(0)\n",
    "        # create mapper from movie title to index\n",
    "        hashmap = {\n",
    "            movie: i for i, movie in\n",
    "            enumerate(list(df_movies.set_index('movieId').loc[movie_user_mat.index].title)) # noqa\n",
    "        }\n",
    "        # transform matrix to scipy sparse matrix\n",
    "        movie_user_mat_sparse = csr_matrix(movie_user_mat.values)\n",
    "\n",
    "        # clean up\n",
    "        del df_movies, df_movies_cnt, df_users_cnt\n",
    "        del df_ratings, df_ratings_filtered, movie_user_mat\n",
    "        gc.collect()\n",
    "        return movie_user_mat_sparse, hashmap\n",
    "\n",
    "    def _fuzzy_matching(self, hashmap, fav_movie):\n",
    "        \"\"\"\n",
    "        return the closest match via fuzzy ratio.\n",
    "        If no match found, return None\n",
    "        Parameters\n",
    "        ----------\n",
    "        hashmap: dict, map movie title name to index of the movie in data\n",
    "        fav_movie: str, name of user input movie\n",
    "        Return\n",
    "        ------\n",
    "        index of the closest match\n",
    "        \"\"\"\n",
    "        match_tuple = []\n",
    "        # get match\n",
    "        for title, idx in hashmap.items():\n",
    "            ratio = fuzz.ratio(title.lower(), fav_movie.lower())\n",
    "            if ratio >= 60:\n",
    "                match_tuple.append((title, idx, ratio))\n",
    "        # sort\n",
    "        match_tuple = sorted(match_tuple, key=lambda x: x[2])[::-1]\n",
    "        if not match_tuple:\n",
    "            print('Oops! No match is found')\n",
    "        else:\n",
    "            print('Found possible matches in our database: '\n",
    "                  '{0}\\n'.format([x[0] for x in match_tuple]))\n",
    "            return match_tuple[0][1]\n",
    "\n",
    "    def _inference(self, model, data, hashmap,\n",
    "                   fav_movie, n_recommendations):\n",
    "        \"\"\"\n",
    "        return top n similar movie recommendations based on user's input movie\n",
    "        Parameters\n",
    "        ----------\n",
    "        model: sklearn model, knn model\n",
    "        data: movie-user matrix\n",
    "        hashmap: dict, map movie title name to index of the movie in data\n",
    "        fav_movie: str, name of user input movie\n",
    "        n_recommendations: int, top n recommendations\n",
    "        Return\n",
    "        ------\n",
    "        list of top n similar movie recommendations\n",
    "        \"\"\"\n",
    "        # fit\n",
    "        model.fit(data)\n",
    "        # get input movie index\n",
    "        print('You have input movie:', fav_movie)\n",
    "        idx = self._fuzzy_matching(hashmap, fav_movie)\n",
    "        # inference\n",
    "        print('Recommendation system start to make inference')\n",
    "        print('......\\n')\n",
    "        t0 = time.time()\n",
    "        distances, indices = model.kneighbors(\n",
    "            data[idx],\n",
    "            n_neighbors=n_recommendations+1)\n",
    "        # get list of raw idx of recommendations\n",
    "        raw_recommends = \\\n",
    "            sorted(\n",
    "                list(\n",
    "                    zip(\n",
    "                        indices.squeeze().tolist(),\n",
    "                        distances.squeeze().tolist()\n",
    "                    )\n",
    "                ),\n",
    "                key=lambda x: x[1]\n",
    "            )[:0:-1]\n",
    "        print('It took my system {:.2f}s to make inference \\n\\\n",
    "              '.format(time.time() - t0))\n",
    "        # return recommendation (movieId, distance)\n",
    "        return raw_recommends\n",
    "\n",
    "    def make_recommendations(self, fav_movie, n_recommendations):\n",
    "        \"\"\"\n",
    "        make top n movie recommendations\n",
    "        Parameters\n",
    "        ----------\n",
    "        fav_movie: str, name of user input movie\n",
    "        n_recommendations: int, top n recommendations\n",
    "        \"\"\"\n",
    "        # get data\n",
    "        movie_user_mat_sparse, hashmap = self._prep_data()\n",
    "        # get recommendations\n",
    "        raw_recommends = self._inference(\n",
    "            self.model, movie_user_mat_sparse, hashmap,\n",
    "            fav_movie, n_recommendations)\n",
    "        # print results\n",
    "        reverse_hashmap = {v: k for k, v in hashmap.items()}\n",
    "        print('Recommendations for {}:'.format(fav_movie))\n",
    "        for i, (idx, dist) in enumerate(raw_recommends):\n",
    "            print('{0}: {1}, with distance '\n",
    "                  'of {2}'.format(i+1, reverse_hashmap[idx], dist))\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        prog=\"Movie Recommender\",\n",
    "        description=\"Run KNN Movie Recommender\")\n",
    "    parser.add_argument('--path', nargs='?', default='../data/MovieLens',\n",
    "                        help='input data path')\n",
    "    parser.add_argument('--movies_filename', nargs='?', default='movies.csv',\n",
    "                        help='provide movies filename')\n",
    "    parser.add_argument('--ratings_filename', nargs='?', default='ratings.csv',\n",
    "                        help='provide ratings filename')\n",
    "    parser.add_argument('--movie_name', nargs='?', default='',\n",
    "                        help='provide your favoriate movie name')\n",
    "    parser.add_argument('--top_n', type=int, default=10,\n",
    "                        help='top n movie recommendations')\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # get args\n",
    "    args = parse_args()\n",
    "    data_path = args.path\n",
    "    movies_filename = args.movies_filename\n",
    "    ratings_filename = args.ratings_filename\n",
    "    movie_name = args.movie_name\n",
    "    top_n = args.top_n\n",
    "    # initial recommender system\n",
    "    recommender = KnnRecommender(\n",
    "        os.path.join(data_path, movies_filename),\n",
    "        os.path.join(data_path, ratings_filename))\n",
    "    # set params\n",
    "    recommender.set_filter_params(50, 50)\n",
    "    recommender.set_model_params(20, 'brute', 'cosine', -1)\n",
    "    # make recommendations\n",
    "    recommender.make_recommendations(movie_name, top_n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1acf06c8fd8bc80800f08a72a7dc06ca6ff72dd3d390f63a44d70f4da57fac27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
