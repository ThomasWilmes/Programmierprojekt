{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jsbreite\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning:\n",
      "\n",
      "Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To store the data\n",
    "import pandas as pd\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# To create plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To create interactive plots\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# To shift lists\n",
    "from collections import deque\n",
    "\n",
    "# To compute similarities between vectors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# To use recommender systems\n",
    "import surprise as sp\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# To create deep learning models\n",
    "from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# To create sparse matrices\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# To light fm\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# To stack sparse matrices\n",
    "from scipy.sparse import vstack\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Als Nächstes sollen alle Pfade mit variablen belegt werden, dass macht das austauschen einfacher.\n",
    "\n",
    "movie_tile_File = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/movie_titles.csv'\n",
    "movie_tile_File_new = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Movie_Titles_clear.gzip'\n",
    "combined_data_1 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_1.txt'\n",
    "combined_data_2 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_2.txt'\n",
    "combined_data_3 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_3.txt'\n",
    "combined_data_4 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_4.txt'\n",
    "new_Combined = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Combined_Data_All.gzip'\n",
    "netflix_rating_Combined = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/netflix_data.csv'\n",
    "parquet_combined_data = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/data_Comb.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data into viables\n",
    "\n",
    "combined_data_1_raw = pd.read_csv(combined_data_1, header=None, names=['Cust_Id', 'Rating'], usecols=[0, 1])\n",
    "combined_data_2_raw = pd.read_csv(combined_data_2, header=None, names=['Cust_Id', 'Rating'], usecols=[0, 1])\n",
    "combined_data_3_raw = pd.read_csv(combined_data_3, header=None, names=['Cust_Id', 'Rating'], usecols=[0, 1])\n",
    "combined_data_4_raw = pd.read_csv(combined_data_4, header=None, names=['Cust_Id', 'Rating'], usecols=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combined_DATA_1\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_1_raw[combined_data_1_raw['Rating'].isna()]['Cust_Id'].reset_index()  \n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_1_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_1_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_1 = pd.concat(user_data)\n",
    "del user_data, combined_data_1_raw, combined_data_1, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "# print('Shape User-Ratings:\\t{}'.format(df_1.shape))\n",
    "\n",
    "## Combined_DATA_2\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_2_raw[combined_data_2_raw['Rating'].isna()]['Cust_Id'].reset_index()  ##---> Nachvollziehen\n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_2_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_2_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_2 = pd.concat(user_data)\n",
    "del user_data, combined_data_2_raw, combined_data_2, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "# print('Shape User-Ratings:\\t{}'.format(df_2.shape))\n",
    "\n",
    "## Combined_DATA_3\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_3_raw[combined_data_3_raw['Rating'].isna()]['Cust_Id'].reset_index()  ##---> Nachvollziehen\n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_3_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_3_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_3 = pd.concat(user_data)\n",
    "del user_data, combined_data_3_raw, combined_data_3, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "# print('Shape User-Ratings:\\t{}'.format(df_3.shape))\n",
    "\n",
    "## Combined_DATA_4\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_4_raw[combined_data_4_raw['Rating'].isna()]['Cust_Id'].reset_index()  ##---> Nachvollziehen\n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_4_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_4_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_4 = pd.concat(user_data)\n",
    "del user_data, combined_data_4_raw, combined_data_4, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "print('Shape User-Ratings:\\t{}'.format(df_4.shape))\n",
    "\n",
    "#Zusammenfügen der aller Daten in einer Variable\n",
    "data = [df_1, df_2,df_3,df_4]\n",
    "df = pd.concat(data)\n",
    "del df_1, df_2, df_3, df_4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tile_File = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/movie_titles.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(new_Combined, index= 'False', compression= 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(new_Combined)\n",
    "Convert_dic_data= {'Cust_Id': 'int64', 'Rating': 'float32', 'Movie_Id': 'Int64'}\n",
    "data= data.astype(Convert_dic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Id</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Isle of Man TT 2004 Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Paula Abdul's Get Up &amp; Dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Rise and Fall of ECW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17765</th>\n",
       "      <td>17766</td>\n",
       "      <td>Where the Wild Things Are and Other Maurice Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17766</th>\n",
       "      <td>17767</td>\n",
       "      <td>Fidel Castro: American Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17767</th>\n",
       "      <td>17768</td>\n",
       "      <td>Epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17768</th>\n",
       "      <td>17769</td>\n",
       "      <td>The Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17769</th>\n",
       "      <td>17770</td>\n",
       "      <td>Alien Hunter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17770 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Movie_Id                                               Name\n",
       "0             1                                    Dinosaur Planet\n",
       "1             2                         Isle of Man TT 2004 Review\n",
       "2             3                                          Character\n",
       "3             4                       Paula Abdul's Get Up & Dance\n",
       "4             5                           The Rise and Fall of ECW\n",
       "...         ...                                                ...\n",
       "17765     17766  Where the Wild Things Are and Other Maurice Se...\n",
       "17766     17767                  Fidel Castro: American Experience\n",
       "17767     17768                                              Epoch\n",
       "17768     17769                                        The Company\n",
       "17769     17770                                       Alien Hunter\n",
       "\n",
       "[17770 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie_titles = pd.read_csv(movie_tile_File,\n",
    "                           encoding = \"ISO-8859-1\",\n",
    "                           delimiter= '\\t',\n",
    "                           header = None,\n",
    "                           names = ['Target'])\n",
    "                           \n",
    "                           #on_bad_lines=True) #, \n",
    "                           #engine = 'python',\n",
    "                           #delimiter =',',\n",
    "                           \n",
    "                           #on_bad_lines= 'skip', #Wird gebraucht um Fehlerhafte Title zu behen.\n",
    "                           #names = ['Id', 'Year', 'Name'])#.set_index('Id')\n",
    "\n",
    "movie_titles[['Movie_Id', 'Year', 'Name']] = movie_titles['Target'].str.split(pat=\",\",n=2, expand=True)   \n",
    "movie_titles= movie_titles.drop(['Target', 'Year'], axis= 1)  \n",
    "Convert_dic= {'Movie_Id': 'int64', 'Name': 'str'}\n",
    "movie_titles = movie_titles.astype(Convert_dic)\n",
    "#movie_titles.astype({'Movie_Id': 'int64', 'Name': 'str'}).dtypes\n",
    "#movie_titles.rename(columns={'Id':'Movie_Id'}, inplace=True)\n",
    "#movie_titles = movie_titles.reset_index(drop=True)\n",
    "display(movie_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Movie_Id     int64\n",
       "Name        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles.to_parquet(movie_tile_File_new, index= 'False', compression= 'gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(movie_titles.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 480189 unique users and 17770 unique movies in this data set\n"
     ]
    }
   ],
   "source": [
    "num_users = len(data.Cust_Id.unique())\n",
    "num_items = len(data.Movie_Id.unique())\n",
    "print('There are {} unique users and {} unique movies in this data set'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>4617990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>10132080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>28811247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>33750958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>23168232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count\n",
       "Rating          \n",
       "1.0      4617990\n",
       "2.0     10132080\n",
       "3.0     28811247\n",
       "4.0     33750958\n",
       "5.0     23168232"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings_cnt_tmp = pd.DataFrame(data.groupby('Rating').size(), columns=['count'])\n",
    "df_ratings_cnt_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)\n",
    "print(data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.00    232944.00\n",
       "0.95     29199.60\n",
       "0.90     12303.80\n",
       "0.85      6638.85\n",
       "0.80      4040.20\n",
       "0.75      2667.75\n",
       "0.70      1948.30\n",
       "0.65      1360.00\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rating frequency\n",
    "df_movies_cnt = pd.DataFrame(data.groupby('Movie_Id').size(), columns=['count'])\n",
    "df_movies_cnt.head()\n",
    "df_movies_cnt['count'].quantile(np.arange(1, 0.6, -0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data\n",
    "popularity_thres = 17700\n",
    "popular_movies = list(set(df_movies_cnt.query('count >= @popularity_thres').index))\n",
    "df_ratings_drop_movies = data[data.Movie_Id.isin(popular_movies)]\n",
    "print('shape of original ratings data: ', data.shape)\n",
    "print('shape of ratings data after dropping unpopular movies: ', df_ratings_drop_movies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of ratings given by every user\n",
    "df_users_cnt = pd.DataFrame(df_ratings_drop_movies.groupby('Cust_Id').size(), columns=['count'])\n",
    "df_users_cnt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_cnt['count'].quantile(np.arange(1, 0.5, -0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data\n",
    "ratings_thres = 500\n",
    "active_users = list(set(df_users_cnt.query('count >= @ratings_thres').index))\n",
    "df_ratings_drop_users = df_ratings_drop_movies[df_ratings_drop_movies.Cust_Id.isin(active_users)]\n",
    "print('shape of original ratings data: ', data.shape)\n",
    "print('shape of ratings data after dropping both unpopular movies and inactive users: ', df_ratings_drop_users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape User-Ratings unfiltered:\t(100480507, 3)\n",
      "Shape User-Ratings filtered:\t(55507418, 3)\n"
     ]
    }
   ],
   "source": [
    "df = data\n",
    "# Filter sparse movies\n",
    "min_movie_ratings = 10000\n",
    "filter_movies = (df['Movie_Id'].value_counts()>min_movie_ratings)\n",
    "filter_movies = filter_movies[filter_movies].index.tolist()\n",
    "\n",
    "# Filter sparse users\n",
    "min_user_ratings = 250\n",
    "filter_users = (df['Cust_Id'].value_counts()>min_user_ratings)\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "# Actual filtering\n",
    "df_filterd = df[(df['Movie_Id'].isin(filter_movies)) & (df['Cust_Id'].isin(filter_users))]\n",
    "del filter_movies, filter_users, min_movie_ratings, min_user_ratings\n",
    "\n",
    "\n",
    "print('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\n",
    "print('Shape User-Ratings filtered:\\t{}'.format(df_filterd.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot and create movie-user matrix\n",
    "del data, \n",
    "movie_user_mat = df_filterd.pivot(index='Movie_Id', columns='Cust_Id', values='Rating').fillna(0)\n",
    "\n",
    "# create mapper from movie title to index\n",
    "movie_to_idx = {\n",
    "   movie: i for i, movie in \n",
    "    enumerate(list(movie_titles.set_index('Movie_Id').loc[movie_user_mat.index].Name))\n",
    "}\n",
    "# transform matrix to scipy sparse matrix\n",
    "movie_user_mat_sparse = csr_matrix(movie_user_mat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot and create movie-user matrix\n",
    "movie_user_mat = df_ratings_drop_users.pivot(index='Movie_Id', columns='Cust_Id', values='Rating').fillna(0)\n",
    "\n",
    "# create mapper from movie title to index\n",
    "movie_to_idx = {\n",
    "    movie: i for i, movie in \n",
    "    enumerate(list(movie_titles.set_index('Movie_Id').loc[movie_user_mat.index].Name))\n",
    "}\n",
    "# transform matrix to scipy sparse matrix\n",
    "movie_user_mat_sparse = csr_matrix(movie_user_mat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_matching(mapper, fav_movie, verbose=True):\n",
    "    #https://www.kaggle.com/code/ibtesama/getting-started-with-a-movie-recommendation-system\n",
    "    \"\"\"\n",
    "    return the closest match via fuzzy ratio. If no match found, return None\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    mapper: dict, map movie title name to index of the movie in data\n",
    "\n",
    "    fav_movie: str, name of user input movie\n",
    "    \n",
    "    verbose: bool, print log if True\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    index of the closest match\n",
    "    \"\"\"\n",
    "    match_tuple = []\n",
    "    # get match\n",
    "    for title, idx in mapper.items():\n",
    "        ratio = fuzz.ratio(title.lower(), fav_movie.lower())\n",
    "        if ratio >= 60:\n",
    "            match_tuple.append((title, idx, ratio))\n",
    "    # sort\n",
    "    match_tuple = sorted(match_tuple, key=lambda x: x[2])[::-1]\n",
    "    if not match_tuple:\n",
    "        print('Oops! No match is found')\n",
    "        return\n",
    "    if verbose:\n",
    "        print('Found possible matches in our database: {0}\\n'.format([x[0] for x in match_tuple]))\n",
    "    return match_tuple[0][1]\n",
    "\n",
    "\n",
    "\n",
    "def make_recommendation(model_knn, data, mapper, fav_movie, n_recommendations):\n",
    "    # fit\n",
    "    model_knn.fit(data)\n",
    "    # get input movie index\n",
    "    print('You have input movie:', fav_movie)\n",
    "    idx = fuzzy_matching(mapper, fav_movie, verbose=True)\n",
    "    # inference\n",
    "    print('Recommendation system start to make inference')\n",
    "    print('......\\n')\n",
    "    distances, indices = model_knn.kneighbors(data[idx], n_neighbors=n_recommendations+1)\n",
    "    # get list of raw idx of recommendations\n",
    "    raw_recommends = \\\n",
    "        sorted(list(zip(indices.squeeze().tolist(), distances.squeeze().tolist())), key=lambda x: x[1])[:0:-1]\n",
    "    # get reverse mapper\n",
    "    reverse_mapper = {v: k for k, v in mapper.items()}\n",
    "    # print recommendations\n",
    "    print('Recommendations for {}:'.format(fav_movie))\n",
    "    for i, (idx, dist) in enumerate(raw_recommends):\n",
    "        print('{0}: {1}, with distance of {2}'.format(i+1, reverse_mapper[idx], dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_jobs=-1, n_neighbors=70)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=70, n_jobs=-1)\n",
    "# fit\n",
    "model_knn.fit(movie_user_mat_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have input movie: Doc Hollywood\n",
      "Found possible matches in our database: ['Doc Hollywood', 'Ed Wood']\n",
      "\n",
      "Recommendation system start to make inference\n",
      "......\n",
      "\n",
      "Recommendations for Doc Hollywood:\n",
      "1: Crocodile Dundee, with distance of 0.5253264904022217\n",
      "2: Kindergarten Cop, with distance of 0.5238630771636963\n",
      "3: Overboard, with distance of 0.5229185819625854\n",
      "4: Twins, with distance of 0.5144147872924805\n",
      "5: The Secret of My Success, with distance of 0.5063148140907288\n"
     ]
    }
   ],
   "source": [
    "my_favorite = 'Doc Hollywood'\n",
    "\n",
    "make_recommendation(\n",
    "    model_knn=model_knn,\n",
    "    data=movie_user_mat_sparse,\n",
    "    fav_movie=my_favorite,\n",
    "    mapper=movie_to_idx,\n",
    "    n_recommendations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NearestNeighbors' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jsbreite\\OneDrive - Jannis Breitenstein IT\\Hochschule_Studium\\5_Semester\\Programmierprojekt\\Codes\\Github\\Best_Of.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Best_Of.ipynb#X46sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# load the model from disk\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Best_Of.ipynb#X46sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m loaded_model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mknnpickle_file\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jsbreite/OneDrive%20-%20Jannis%20Breitenstein%20IT/Hochschule_Studium/5_Semester/Programmierprojekt/Codes/Github/Best_Of.ipynb#X46sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m result \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39;49mpredict(movie_user_mat_sparse)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NearestNeighbors' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "## Läuft nicht!!!\n",
    "# https://datascience.stackexchange.com/questions/52704/how-to-save-a-knn-model\n",
    "\n",
    "\"\"\"\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "\"\"\"\n",
    "#model_knn = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=70, n_jobs=-1)\n",
    "# fit\n",
    "#model_knn.fit(movie_user_mat_sparse)\n",
    "\"\"\"\n",
    "knn = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=70, n_jobs=-1)\n",
    "knn.fit(movie_user_mat_sparse)\n",
    "\n",
    "# Its important to use binary mode \n",
    "knnpickle_file = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/KNN-Model.sav'\n",
    "knnPickle = open('knnpickle_file', 'wb') \n",
    "\n",
    "# source, destination \n",
    "pickle.dump(knn, knnPickle)  \n",
    "\n",
    "# close the file\n",
    "knnPickle.close()\n",
    "                \n",
    "      \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open('knnpickle_file', 'rb'))\n",
    "result = loaded_model.predict(movie_user_mat_sparse) \n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1acf06c8fd8bc80800f08a72a7dc06ca6ff72dd3d390f63a44d70f4da57fac27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
