{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "#https://www.kaggle.com/code/heeraldedhia/movie-ratings-and-recommendation-using-knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store the data\n",
    "import pandas as pd\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# To create plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To create interactive plots\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# To shift lists\n",
    "from collections import deque\n",
    "\n",
    "# To compute similarities between vectors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# To use recommender systems\n",
    "import surprise as sp\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# To create deep learning models\n",
    "from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# To create sparse matrices\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# To light fm\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# To stack sparse matrices\n",
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wenn Colabs benutzt wird, kann es damit verbunden werden\n",
    "\n",
    "movie_tile_File = '/content/drive/MyDrive/Programmieprojekt/movie_titles.csv'\n",
    "movie_tile_File_new = '/content/drive/MyDrive/Programmieprojekt/movie_titles_new.csv'\n",
    "combined_data_1 = '/content/drive/MyDrive/Programmieprojekt/combined_data_1.txt'\n",
    "combined_data_2 = '/content/drive/MyDrive/Programmieprojekt/combined_data_2.txt'\n",
    "combined_data_3 = '/content/drive/MyDrive/Programmieprojekt/combined_data_3.txt'\n",
    "combined_data_4 = '/content/drive/MyDrive/Programmieprojekt/combined_data_4.txt'\n",
    "new_Combined = '/content/drive/MyDrive/Programmieprojekt/Cobined_data_new_v1.csv'\n",
    "netflix_rating_Combined = '/content/drive/MyDrive/Programmieprojekt/netflix_data.csv'\n",
    "parquet_combined_data = '/content/drive/MyDrive/Programmieprojekt/data_Comb.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Als Nächstes sollen alle Pfade mit variablen belegt werden, dass macht das austauschen einfacher.\n",
    "\n",
    "movie_tile_File = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/movie_titles.csv'\n",
    "movie_tile_File_new = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/movie_titles_new.csv'\n",
    "combined_data_1 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_1.txt'\n",
    "combined_data_2 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_2.txt'\n",
    "combined_data_3 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_3.txt'\n",
    "combined_data_4 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_4.txt'\n",
    "new_Combined = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Cobined_data_new_v1.csv'\n",
    "netflix_rating_Combined = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/netflix_data.csv'\n",
    "parquet_combined_data = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/data_Comb.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data into viables\n",
    "\n",
    "combined_data_1_raw = pd.read_csv(combined_data_1, header=None, names=['Cust_Id', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "combined_data_2_raw = pd.read_csv(combined_data_2, header=None, names=['Cust_Id', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "combined_data_3_raw = pd.read_csv(combined_data_3, header=None, names=['Cust_Id', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "combined_data_4_raw = pd.read_csv(combined_data_4, header=None, names=['Cust_Id', 'Rating', 'Date'], usecols=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape User-Ratings:\t(26847523, 4)\n",
      "          Cust_Id  Rating        Date  Movie_Id\n",
      "26851921  1790158     4.0  2005-11-01     17770\n",
      "26851922  1608708     3.0  2005-07-19     17770\n",
      "26851923   234275     1.0  2004-08-07     17770\n",
      "26851924   255278     4.0  2004-05-28     17770\n",
      "26851925   453585     2.0  2005-03-10     17770\n",
      "   Cust_Id  Rating        Date  Movie_Id\n",
      "1  1488844     3.0  2005-09-06         1\n",
      "2   822109     5.0  2005-05-13         1\n",
      "3   885013     4.0  2005-10-19         1\n",
      "4    30878     4.0  2005-12-26         1\n",
      "5   823519     3.0  2004-05-03         1\n"
     ]
    }
   ],
   "source": [
    "## Combined_DATA_1\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_1_raw[combined_data_1_raw['Rating'].isna()]['Cust_Id'].reset_index()  \n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_1_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_1_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_1 = pd.concat(user_data)\n",
    "del user_data, combined_data_1_raw, combined_data_1, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "# print('Shape User-Ratings:\\t{}'.format(df_1.shape))\n",
    "\n",
    "## Combined_DATA_2\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_2_raw[combined_data_2_raw['Rating'].isna()]['Cust_Id'].reset_index()  ##---> Nachvollziehen\n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_2_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_2_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_2 = pd.concat(user_data)\n",
    "del user_data, combined_data_2_raw, combined_data_2, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "# print('Shape User-Ratings:\\t{}'.format(df_2.shape))\n",
    "\n",
    "## Combined_DATA_3\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_3_raw[combined_data_3_raw['Rating'].isna()]['Cust_Id'].reset_index()  ##---> Nachvollziehen\n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_3_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_3_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_3 = pd.concat(user_data)\n",
    "del user_data, combined_data_3_raw, combined_data_3, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "# print('Shape User-Ratings:\\t{}'.format(df_3.shape))\n",
    "\n",
    "## Combined_DATA_4\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = combined_data_4_raw[combined_data_4_raw['Rating'].isna()]['Cust_Id'].reset_index()  ##---> Nachvollziehen\n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = combined_data_4_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = combined_data_4_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie_Id'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df_4 = pd.concat(user_data)\n",
    "del user_data, combined_data_4_raw, combined_data_4, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "print('Shape User-Ratings:\\t{}'.format(df_4.shape))\n",
    "\n",
    "#Zusammenfügen der aller Daten in einer Variable\n",
    "data = [df_1, df_2,df_3,df_4]\n",
    "df = pd.concat(data)\n",
    "del df_1, df_2, df_3, df_4\n",
    "print(df.tail(5))\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cust_Id  Rating        Date  Movie_Id  Index\n",
      "1  1488844     3.0  2005-09-06         1      1\n",
      "2   822109     5.0  2005-05-13         1      2\n",
      "3   885013     4.0  2005-10-19         1      3\n",
      "4    30878     4.0  2005-12-26         1      4\n",
      "5   823519     3.0  2004-05-03         1      5\n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  Cust_Id  Rating        Date  Movie_Id  Index\n",
      "0      1  1488844     3.0  2005-09-06         1      1\n",
      "1      2   822109     5.0  2005-05-13         1      2\n",
      "2      3   885013     4.0  2005-10-19         1      3\n",
      "3      4    30878     4.0  2005-12-26         1      4\n",
      "4      5   823519     3.0  2004-05-03         1      5\n"
     ]
    }
   ],
   "source": [
    "print(test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for all movies\n",
    "from multiprocessing import dummy\n",
    "\n",
    "\n",
    "movie_titles = pd.read_csv(movie_tile_File, \n",
    "                           encoding = 'ISO-8859-1', \n",
    "                           engine = 'python',\n",
    "                           delimiter =',',\n",
    "                           header = None, \n",
    "                           on_bad_lines= 'skip', #Wird gebraucht um Fehlerhafte Title zu behen.\n",
    "\n",
    "                           names = ['Id', 'Year', 'Name']).set_index('Id')\n",
    "                           \n",
    "\n",
    "print('Shape Movie-Titles:\\t{}'.format(movie_titles.shape))\n",
    "\n",
    "#Zwischenspeichern der Movies, um fehlerhafte Liste zu bearbeiten\n",
    "movie_titles.to_csv(movie_tile_File_new,encoding = 'ISO-8859-1',sep=';')\n",
    "\n",
    "movie_titles.rename(columns={'Id':'Movie_Id'}, inplace=True)\n",
    "\n",
    "display(movie_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter sparse movies\n",
    "min_movie_ratings = 10000\n",
    "filter_movies = (df['Movie_Id'].value_counts()>min_movie_ratings)\n",
    "filter_movies = filter_movies[filter_movies].index.tolist()\n",
    "\n",
    "# Filter sparse users\n",
    "min_user_ratings = 250\n",
    "filter_users = (df['Cust_Id'].value_counts()>min_user_ratings)\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "# Actual filtering\n",
    "df_filterd = df[(df['Movie_Id'].isin(filter_movies)) & (df['Cust_Id'].isin(filter_users))]\n",
    "del filter_movies, filter_users, min_movie_ratings, min_user_ratings\n",
    "\n",
    "\n",
    "print('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\n",
    "print('Shape User-Ratings filtered:\\t{}'.format(df_filterd.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movie_Gerne = pd.read_table('C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/IDMB/title.basics.tsv')\n",
    "genres = Movie_Gerne.drop(['tconst', 'titleType', 'isAdult','startYear', 'endYear', 'runtimeMinutes', 'primaryTitle'],axis =1)\n",
    "del Movie_Gerne\n",
    "genres['genres'] = genres['genres'].str.split(',').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('movie_titles Bevor Duplicates\\t{}'.format(movie_titles.shape))\n",
    "\n",
    "movie_titles = movie_titles.drop_duplicates(subset=['Year', 'Name'],keep='first')\n",
    "print('movie_titles Nach entfernen Duplicates\\t{}'.format(movie_titles.shape))\n",
    "\n",
    "data = pd.merge(pd.DataFrame(movie_titles), pd.DataFrame(genres), left_on=['Name'], \n",
    "             right_on= ['originalTitle'], how='left')\n",
    "print(data.head(5))\n",
    "print(movie_titles.head(5))\n",
    "print('Data\\t{}'.format(data.shape))\n",
    "print('movie_titles\\t{}'.format(movie_titles.shape))\n",
    "##aa\n",
    "data = data.drop_duplicates(subset=['Name'],keep='first')\n",
    "print('Data\\t{}'.format(data.shape))\n",
    "print('movie_titles\\t{}'.format(movie_titles.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data = pd.merge(pd.DataFrame(data), pd.DataFrame(df), left_on=['Id'], \n",
    "             right_on= ['Id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12,10))\n",
    "list1 = []\n",
    "for i in data['genres']:\n",
    "    list1.extend(i)\n",
    "ax = pd.Series(list1).value_counts()[:10].sort_values(ascending=True).plot.barh(width=0.9,color=sns.color_palette('hls',10))\n",
    "for i, v in enumerate(pd.Series(list1).value_counts()[:10].sort_values(ascending=True).values): \n",
    "    ax.text(.8, i, v,fontsize=12,color='white',weight='bold')\n",
    "plt.title('Top Genres')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/code/heeraldedhia/movie-ratings-and-recommendation-using-knn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import base64\n",
    "import io\n",
    "from matplotlib.pyplot import imread\n",
    "import codecs\n",
    "from IPython.display import HTML\n",
    "\n",
    "from surprise import Reader\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "data = Dataset.load_from_df(df[['Cust_Id', 'Movie_Id', 'Rating']], reader)\n",
    "data.split(n_folds=10)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1acf06c8fd8bc80800f08a72a7dc06ca6ff72dd3d390f63a44d70f4da57fac27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
