{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install  Packets\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install lightfm\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install surprise\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install scikit-surprise \n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install google.colab\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install plotly\n",
    "!{sys.executable} -m pip install fastparquet\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install pylance\n",
    "!{sys.executable} -m pip install python-Levenshtein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store the data\n",
    "import pandas as pd\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# To create plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To create interactive plots\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# To shift lists\n",
    "from collections import deque\n",
    "\n",
    "# To compute similarities between vectors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# To use recommender systems\n",
    "import surprise as sp\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# To create deep learning models\n",
    "from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# To create sparse matrices\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# To light fm\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# To stack sparse matrices\n",
    "from scipy.sparse import vstack\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Als Nächstes sollen alle Pfade mit variablen belegt werden, dass macht das austauschen einfacher.\n",
    "\n",
    "movie_tile_File = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/movie_titles.csv'\n",
    "movie_tile_File_new = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Movie_Titles_clear.gzip'\n",
    "combined_data_1 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_1.txt'\n",
    "combined_data_2 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_2.txt'\n",
    "combined_data_3 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_3.txt'\n",
    "combined_data_4 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_4.txt'\n",
    "new_Combined = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Combined_Data_All.gzip'\n",
    "netflix_rating_Combined = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/netflix_data.csv'\n",
    "parquet_combined_data = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/data_Comb.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(new_Combined)\n",
    "Convert_dic_data= {'Cust_Id': 'int64', 'Rating': 'float32', 'Movie_Id': 'Int64'}\n",
    "data= data.astype(Convert_dic_data)\n",
    "del new_Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = pd.read_csv(movie_tile_File,\n",
    "                           encoding = \"ISO-8859-1\",\n",
    "                           delimiter= '\\t',\n",
    "                           header = None,\n",
    "                           names = ['Target'])\n",
    "                           # Speicher alle Daten erst in eine Reihe, danach trennt er diese\n",
    "movie_titles[['Movie_Id', 'Year', 'Name']] = movie_titles['Target'].str.split(pat=\",\",n=2, expand=True)   \n",
    "movie_titles= movie_titles.drop(['Target', 'Year'], axis= 1)  \n",
    "Convert_dic= {'Movie_Id': 'int64', 'Name': 'str'}\n",
    "movie_titles = movie_titles.astype(Convert_dic)\n",
    "#movie_titles.astype({'Movie_Id': 'int64', 'Name': 'str'}).dtypes\n",
    "#movie_titles.rename(columns={'Id':'Movie_Id'}, inplace=True)\n",
    "#movie_titles = movie_titles.reset_index(drop=True)\n",
    "display(movie_titles)\n",
    "\n",
    "del Convert_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(data.Cust_Id.unique())\n",
    "num_items = len(data.Movie_Id.unique())\n",
    "print('There are {} unique users and {} unique movies in this data set'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_cnt_tmp = pd.DataFrame(data.groupby('Rating').size(), columns=['count'])\n",
    "df_ratings_cnt_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)\n",
    "print(data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rating frequency\n",
    "df_movies_cnt = pd.DataFrame(data.groupby('Movie_Id').size(), columns=['count'])\n",
    "df_movies_cnt.head()\n",
    "df_movies_cnt['count'].quantile(np.arange(1, 0.6, -0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data\n",
    "popularity_thres = 17700\n",
    "popular_movies = list(set(df_movies_cnt.query('count >= @popularity_thres').index))\n",
    "df_ratings_drop_movies = data[data.Movie_Id.isin(popular_movies)]\n",
    "print('shape of original ratings data: ', data.shape)\n",
    "print('shape of ratings data after dropping unpopular movies: ', df_ratings_drop_movies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of ratings given by every user\n",
    "df_users_cnt = pd.DataFrame(df_ratings_drop_movies.groupby('Cust_Id').size(), columns=['count'])\n",
    "df_users_cnt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_cnt['count'].quantile(np.arange(1, 0.5, -0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data\n",
    "ratings_thres = 500\n",
    "active_users = list(set(df_users_cnt.query('count >= @ratings_thres').index))\n",
    "df_ratings_drop_users = df_ratings_drop_movies[df_ratings_drop_movies.Cust_Id.isin(active_users)]\n",
    "print('shape of original ratings data: ', data.shape)\n",
    "print('shape of ratings data after dropping both unpopular movies and inactive users: ', df_ratings_drop_users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data\n",
    "# Filter sparse movies\n",
    "min_movie_ratings = 1000\n",
    "filter_movies = (df['Movie_Id'].value_counts()>min_movie_ratings)\n",
    "filter_movies = filter_movies[filter_movies].index.tolist()\n",
    "\n",
    "# Filter sparse users\n",
    "min_user_ratings = 200\n",
    "filter_users = (df['Cust_Id'].value_counts()>min_user_ratings)\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "# Actual filtering\n",
    "df_filterd = df[(df['Movie_Id'].isin(filter_movies)) & (df['Cust_Id'].isin(filter_users))]\n",
    "\n",
    "print('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\n",
    "print('Shape User-Ratings filtered:\\t{}'.format(df_filterd.shape))\n",
    "del filter_movies, filter_users, min_movie_ratings, min_user_ratings, data, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie_id_list = df_filterd.Movie_Id.unique().tolist()\n",
    "df_movie_id_list = pd.DataFrame(df_movie_id_list)\n",
    "print(df_movie_id_list.head(4))\n",
    "# Alle movie_Ids die überprüft werden müssen. Alle IDs, werden in ein DataFrame gespeichert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot and create movie-user matrix\n",
    "\n",
    "\n",
    "\n",
    "movie_user_mat = df_filterd.pivot(index='Movie_Id', columns='Cust_Id', values='Rating').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.       Pivot Tabelle, wobei die Movie_IDs Index sind  ( list(movie_user_mat.index.values))\n",
    "## 1.1.     Für jeden Film müssen die nächsten Nachbarn berechnet werden. \n",
    "#  1.2.     Die Iteration der Berechnung soll mit Hilfe des Index in der Tabelle movie_user_mat geschehen. \n",
    "#  2.       Für die nächsten nachbarn soll eine Liste erstellt werden. \n",
    "# 2.1.      Jede Berechnung bzw. die Ergebnisse sollen in eine neue Liste gepackt werden. Spricht alle Iterationen sollen in eine Liste zwischengespeichert werden und am Ende in eine CSV Exportiert werden.\n",
    "\n",
    "\n",
    "#https://github.com/aniketng21/Movie-Recommendation-System-Using-KNN-Algorithm/blob/master/Movie_Recommendation_System.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_index_list = list(movie_user_mat.index.values)\n",
    "# Get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose random movie.\n",
    "#query_index = 8585\n",
    "#query_index = (movie_user_mat.shape[0])\n",
    "# Haiku Tunnel 6899 .95 Precision\n",
    "\n",
    "query_index = np.random.choice(movie_user_mat.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Choosen Movie is: \",movie_user_mat.index[query_index])\n",
    "\n",
    "print(movie_user_mat.index[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_table_matrix = csr_matrix(movie_user_mat.values)\n",
    "model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'auto',n_jobs=-1)\n",
    "model_knn.fit(user_movie_table_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(columns=['Movie_Id', 'R_Movie_Id_1', 'R_Distance_1' , 'R_Movie_Id_2'  , 'R_Distance_2' , 'R_Movie_Id_3'  ,'R_Distance_3','R_Movie_Id_4' ,'R_Distance_4' ,'R_Movie_Id_5' ,'R_Distance_5'])\n",
    "Convert_dic= {'Movie_Id': 'int32', 'R_Movie_Id_1': 'int32','R_Distance_1':'float','R_Movie_Id_2': 'int32','R_Distance_2':'float','R_Movie_Id_3': 'int32','R_Distance_3':'float','R_Movie_Id_4': 'int32','R_Distance_4':'float','R_Movie_Id_5': 'int32','R_Distance_5':'float' }\n",
    "df = df.astype(Convert_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Dataframe List\n",
    "\n",
    "for movie_id in movie_index_list:\n",
    "    #print(movie_id)\n",
    "    movie_id_mat = movie_user_mat.loc[[movie_id]].values.reshape(1,-1)\n",
    "    distances, indices = model_knn.kneighbors(movie_id_mat, n_neighbors = 120)\n",
    "    movie = []\n",
    "    distance = []\n",
    "    \n",
    "\n",
    "    for i in range(0, len(distances.flatten())):\n",
    "        if i != 0:\n",
    "            movie.append(movie_user_mat.index[indices.flatten()[i]])\n",
    "            distance.append(distances.flatten()[i])    \n",
    "\n",
    "    m=pd.Series(movie,name='Movie_Id')\n",
    "    d=pd.Series(distance,name='distance')\n",
    "    recommend = pd.concat([m,d], axis=1)\n",
    "    recommend = recommend.sort_values('distance',ascending=False)\n",
    "\n",
    "\n",
    "    df = df.append({'Movie_Id': movie_id, 'R_Movie_Id_1': recommend['Movie_Id'].iloc[0], 'R_Distance_1':recommend['distance'].iloc[0],\n",
    "        'R_Movie_Id_2': recommend['Movie_Id'].iloc[1], 'R_Distance_2':recommend['distance'].iloc[1],\n",
    "        'R_Movie_Id_3': recommend['Movie_Id'].iloc[2], 'R_Distance_3':recommend['distance'].iloc[2],\n",
    "        'R_Movie_Id_4': recommend['Movie_Id'].iloc[3], 'R_Distance_4':recommend['distance'].iloc[3],\n",
    "        'R_Movie_Id_5': recommend['Movie_Id'].iloc[4], 'R_Distance_5':recommend['distance'].iloc[4]\n",
    "        },ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convert_dic= {'Movie_Id': 'int32', 'R_Movie_Id_1': 'int32','R_Distance_1':'float','R_Movie_Id_2': 'int32','R_Distance_2':'float','R_Movie_Id_3': 'int32','R_Distance_3':'float','R_Movie_Id_4': 'int32','R_Distance_4':'float','R_Movie_Id_5': 'int32','R_Distance_5':'float' }\n",
    "df = df.astype(Convert_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rounded = df.round({'R_Distance_1': 4, 'R_Distance_2':4,'R_Distance_3': 4, 'R_Distance_4':4,'R_Distance_5':4 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Movie_Recommendations.zip',index= 'False', compression= 'gzip')\n",
    "df.to_csv('C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Movie_Recommendations_header.csv',index= False,sep=';',header='True')\n",
    "df_rounded.to_csv('C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Movie_Recommendations_header_rounded.csv',index= False, sep=';',header='True', decimal=',')\n",
    "df.to_parquet('C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Movie_Recommendations_index.zip',index= 'True', compression= 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_rounded.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rounded.to_csv('C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Movie_Recommendations_header_rounded_name.csv',index= False, sep=';',header='True', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rounded['Movie_Id'] = df_rounded['Movie_Id'].map(movie_titles.set_index('Movie_Id')['Name'])\n",
    "df_rounded['R_Movie_Id_1'] = df_rounded['R_Movie_Id_1'].map(movie_titles.set_index('Movie_Id')['Name'])\n",
    "df_rounded['R_Movie_Id_2'] = df_rounded['R_Movie_Id_2'].map(movie_titles.set_index('Movie_Id')['Name'])\n",
    "df_rounded['R_Movie_Id_3'] = df_rounded['R_Movie_Id_3'].map(movie_titles.set_index('Movie_Id')['Name'])\n",
    "df_rounded['R_Movie_Id_4'] = df_rounded['R_Movie_Id_4'].map(movie_titles.set_index('Movie_Id')['Name'])\n",
    "df_rounded['R_Movie_Id_5'] = df_rounded['R_Movie_Id_5'].map(movie_titles.set_index('Movie_Id')['Name'])\n",
    "print(df_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not Good Code\n",
    "#\n",
    "#\n",
    "movie_list  = {}\n",
    "for movie_id in movie_index_list[:5]:\n",
    "    #print(movie_id)\n",
    "    movie_id_mat = movie_user_mat.loc[[movie_id]].values.reshape(1,-1)\n",
    "    distances, indices = model_knn.kneighbors(movie_id_mat, n_neighbors = 60)\n",
    "    movie_list[movie_id] = []\n",
    "    movie = []\n",
    "    distance = []\n",
    "    \n",
    "\n",
    "    for i in range(0, len(distances.flatten())):\n",
    "        if i != 0:\n",
    "            movie.append(movie_user_mat.index[indices.flatten()[i]])\n",
    "            distance.append(distances.flatten()[i])    \n",
    "\n",
    "    m=pd.Series(movie,name='Movie_Id')\n",
    "    d=pd.Series(distance,name='distance')\n",
    "    recommend = pd.concat([m,d], axis=1)\n",
    "    recommend = recommend.sort_values('distance',ascending=False)\n",
    "\n",
    "    print('Recommendations for {0}:\\n'.format(movie_id))\n",
    "    #test_list.append(movie_id, recommend['Movie_Id'].iloc[i], recommend['distance'].iloc[i],recommend['Movie_Id'].iloc[1+i], recommend['distance'].iloc[1+i])\n",
    "   \n",
    "    df = df.append({'Movie_Id': movie_id, 'R_Movie_Id_1': recommend['Movie_Id'].iloc[0], 'R_Distance_1':recommend['distance'].iloc[0],\n",
    "        'R_Movie_Id_2': recommend['Movie_Id'].iloc[1], 'R_Distance_2':recommend['distance'].iloc[1],\n",
    "        'R_Movie_Id_3': recommend['Movie_Id'].iloc[2], 'R_Distance_3':recommend['distance'].iloc[2],\n",
    "        'R_Movie_Id_4': recommend['Movie_Id'].iloc[3], 'R_Distance_4':recommend['distance'].iloc[3],\n",
    "        'R_Movie_Id_5': recommend['Movie_Id'].iloc[4], 'R_Distance_5':recommend['distance'].iloc[4]\n",
    "        },ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(0,5):\n",
    "        #df= df.append({'Movie_Id': movie_id})\n",
    "        movie_list[movie_id].append({'Movie_Id': recommend['Movie_Id'].iloc[i], 'distance': recommend['distance'].iloc[i]})\n",
    "\n",
    "        #df = pf.dataframe({'Movie_ID': [movie_id, recommend['Movie_Id'].iloc[i]]})\n",
    "        \n",
    "        print('{0}: {1}, with distance of {2}'.format(i, recommend[\"Movie_Id\"].iloc[i], recommend[\"distance\"].iloc[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(movie_list)\n",
    "recommendation_list = pd.DataFrame(movie_list).transpose()\n",
    "print(recommendation_list.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_user_mat.iloc[query_index,:].values.reshape(1,-1))\n",
    "\n",
    "print(movie_user_mat.index[[1406]])\n",
    "print(movie_user_mat.iloc[[1406]].values.reshape(1,-1))\n",
    "print(movie_user_mat.shape)\n",
    "print(query_index)\n",
    "\n",
    "#Heute aebnd verstehen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(movie_user_mat.index[3,:].values.reshape(1,-1))\n",
    "print(\"Choosen Movie is: \",movie_user_mat.index[query_index])\n",
    "print(movie_user_mat.iloc[1406,:].values.reshape(1,-1))\n",
    "\n",
    "print(movie_user_mat.iloc[query_index,:].values.reshape(1,-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration aufbauen\n",
    "distances, indices = model_knn.kneighbors(movie_user_mat.iloc[query_index,:].values.reshape(1,-1), n_neighbors = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = model_knn.kneighbors(test_jannis, n_neighbors = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Muss durch jeden Film ausgeführt werden Iteration ausgeführt werden.\n",
    "distances, indices = model_knn.kneighbors(movie_user_mat, n_neighbors = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in Movie_index_list:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list = {}\n",
    "\n",
    "\n",
    "for name_movie, values in movie_user_mat.iteritems():\n",
    "    movie_list[name_movie] = []\n",
    "    movie = []\n",
    "    distance = []\n",
    "\n",
    "    for i in range(0, len(distances.flatten())):\n",
    "        if i != 0:\n",
    "            movie.append(movie_user_mat.index[indices.flatten()[i]])\n",
    "            distance.append(distances.flatten()[i])    \n",
    "\n",
    "    m=pd.Series(movie,name='Movie_Id')\n",
    "    d=pd.Series(distance,name='distance')\n",
    "    recommend = pd.concat([m,d], axis=1)\n",
    "    recommend = recommend.sort_values('distance',ascending=False)\n",
    "\n",
    "    print('Recommendations for {0}:\\n'.format(movie_user_mat.index[query_index]))\n",
    "    \n",
    "\n",
    "    for i in range(0,5):\n",
    "        movie_list[name_movie].append({\"Movie_Id\": recommend[\"Movie_Id\"].iloc[i], \"distance\": recommend[\"distance\"].iloc[i]})\n",
    "        print('{0}: {1}, with distance of {2}'.format(i, recommend[\"Movie_Id\"].iloc[i], recommend[\"distance\"].iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Backup\n",
    "movie = []\n",
    "distance = []\n",
    "\n",
    "for i in range(0, len(distances.flatten())):\n",
    "    if i != 0:\n",
    "        movie.append(movie_user_mat.index[indices.flatten()[i]])\n",
    "        distance.append(distances.flatten()[i])    \n",
    "\n",
    "m=pd.Series(movie,name='Movie_Id')\n",
    "d=pd.Series(distance,name='distance')\n",
    "recommend = pd.concat([m,d], axis=1)\n",
    "recommend = recommend.sort_values('distance',ascending=False)\n",
    "\n",
    "print('Recommendations for {0}:\\n'.format(movie_user_mat.index[query_index]))\n",
    "for i in range(0,recommend.shape[0]):\n",
    "    print('{0}: {1}, with distance of {2}'.format(i, recommend[\"Movie_Id\"].iloc[i], recommend[\"distance\"].iloc[i]))\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grundgedanke... Es gibt eine Matrix mit 17700 Filmen (Movie_IDs), jeder Film soll mit einem Title im DataFrame movie_titles verbunden werden. \n",
    "# Jeder Film soll einmal durch das Modell \"K-NN\" laufen und in einem neuem Dataframe gespeichert werden. Sodass ein neuer DataFrame entsteht, wo in der Erste Spalte der Film steht und in den weiteren 5 Spalten die Empfehlung + Distance\n",
    "\n",
    "# zu jeden Film sollen 5 weitere Filme vorgeschlagen werden.! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kann vernachlässigt werden....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot and create movie-user matrix\n",
    "#del data, \n",
    "movie_user_mat = df_filterd.pivot(index='Movie_Id', columns='Cust_Id', values='Rating').fillna(0)\n",
    "\n",
    "# create mapper from movie title to index\n",
    "movie_to_idx = {\n",
    "   movie: i for i, movie in \n",
    "    enumerate(list(movie_titles.set_index('Movie_Id').loc[movie_user_mat.index].Name))\n",
    "}\n",
    "# transform matrix to scipy sparse matrix\n",
    "movie_user_mat_sparse = csr_matrix(movie_user_mat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_matching(mapper, fav_movie, verbose=True):\n",
    "    #https://www.kaggle.com/code/ibtesama/getting-started-with-a-movie-recommendation-system\n",
    "    #https://www.kaggle.com/code/razor08/knn-based-collaborative-filtering?scriptVersionId=81850169  Wo kommmt der Code her\n",
    "    \"\"\"\n",
    "    return the closest match via fuzzy ratio. If no match found, return None\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    mapper: dict, map movie title name to index of the movie in data\n",
    "\n",
    "    fav_movie: str, name of user input movie\n",
    "    \n",
    "    verbose: bool, print log if True\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    index of the closest match\n",
    "    \"\"\"\n",
    "    match_tuple = []\n",
    "    # get match\n",
    "    for title, idx in mapper.items():\n",
    "        ratio = fuzz.ratio(title.lower(), fav_movie.lower())\n",
    "        if ratio >= 60:\n",
    "            match_tuple.append((title, idx, ratio))\n",
    "    # sort\n",
    "    match_tuple = sorted(match_tuple, key=lambda x: x[2])[::-1]\n",
    "    if not match_tuple:\n",
    "        print('Oops! No match is found')\n",
    "        return\n",
    "    if verbose:\n",
    "        print('Found possible matches in our database: {0}\\n'.format([x[0] for x in match_tuple]))\n",
    "    return match_tuple[0][1]\n",
    "\n",
    "\n",
    "\n",
    "def make_recommendation(model_knn, data, mapper, fav_movie, n_recommendations):\n",
    "    # fit\n",
    "    model_knn.fit(data)\n",
    "    # get input movie index\n",
    "    print('You have input movie:', fav_movie)\n",
    "    idx = fuzzy_matching(mapper, fav_movie, verbose=True)\n",
    "    # inference\n",
    "    print('Recommendation system start to make inference')\n",
    "    print('......\\n')\n",
    "    distances, indices = model_knn.kneighbors(data[idx], n_neighbors=n_recommendations+1)\n",
    "    # get list of raw idx of recommendations\n",
    "    raw_recommends = \\\n",
    "        sorted(list(zip(indices.squeeze().tolist(), distances.squeeze().tolist())), key=lambda x: x[1])[:0:-1]\n",
    "    # get reverse mapper\n",
    "    reverse_mapper = {v: k for k, v in mapper.items()}\n",
    "    # print recommendations\n",
    "    print('Recommendations for {}:'.format(fav_movie))\n",
    "    for i, (idx, dist) in enumerate(raw_recommends):\n",
    "        print('{0}: {1}, with distance of {2}'.format(i+1, reverse_mapper[idx], dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=120, n_jobs=-1)\n",
    "# fit\n",
    "model_knn.fit(movie_user_mat_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_favorite = 'Haiku Tunnel'\n",
    "\n",
    "make_recommendation(\n",
    "    model_knn=model_knn,\n",
    "    data=movie_user_mat_sparse,\n",
    "    fav_movie=my_favorite,\n",
    "    mapper=movie_to_idx,\n",
    "    n_recommendations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Läuft nicht!!!\n",
    "# https://datascience.stackexchange.com/questions/52704/how-to-save-a-knn-model\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "\"\"\"\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=70, n_jobs=-1)\n",
    "# fit\n",
    "model_knn.fit(movie_user_mat_sparse)\n",
    "\"\"\"\n",
    "knn = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=70, n_jobs=-1)\n",
    "knn.fit(movie_user_mat_sparse)\n",
    "\n",
    "# Its important to use binary mode \n",
    "knnpickle_file = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/KNN-Model.sav'\n",
    "knnPickle = open('knnpickle_file', 'wb') \n",
    "\n",
    "# source, destination \n",
    "pickle.dump(knn, knnPickle)  \n",
    "\n",
    "# close the file\n",
    "knnPickle.close()\n",
    "                \n",
    "      \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open('knnpickle_file', 'rb'))\n",
    "result = loaded_model.predict(movie_user_mat_sparse) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1acf06c8fd8bc80800f08a72a7dc06ca6ff72dd3d390f63a44d70f4da57fac27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
