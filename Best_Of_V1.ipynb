{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install  Packets\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install lightfm\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install surprise\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install scikit-surprise \n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install google.colab\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install plotly\n",
    "!{sys.executable} -m pip install fastparquet\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install pylance\n",
    "!{sys.executable} -m pip install python-Levenshtein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store the data\n",
    "import pandas as pd\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# To create plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To create interactive plots\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# To shift lists\n",
    "from collections import deque\n",
    "\n",
    "# To compute similarities between vectors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# To use recommender systems\n",
    "import surprise as sp\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# To create deep learning models\n",
    "from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# To create sparse matrices\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# To light fm\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# To stack sparse matrices\n",
    "from scipy.sparse import vstack\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Als Nächstes sollen alle Pfade mit variablen belegt werden, dass macht das austauschen einfacher.\n",
    "\n",
    "movie_tile_File = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/movie_titles.csv'\n",
    "movie_tile_File_new = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Movie_Titles_clear.gzip'\n",
    "combined_data_1 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_1.txt'\n",
    "combined_data_2 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_2.txt'\n",
    "combined_data_3 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_3.txt'\n",
    "combined_data_4 = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/combined_data_4.txt'\n",
    "new_Combined = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Combined_Data_All.gzip'\n",
    "netflix_rating_Combined = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/netflix_data.csv'\n",
    "parquet_combined_data = 'C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/data_Comb.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(new_Combined)\n",
    "Convert_dic_data= {'Cust_Id': 'int64', 'Rating': 'float32', 'Movie_Id': 'Int64'}\n",
    "data= data.astype(Convert_dic_data)\n",
    "del new_Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Id</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Isle of Man TT 2004 Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Paula Abdul's Get Up &amp; Dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Rise and Fall of ECW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17765</th>\n",
       "      <td>17766</td>\n",
       "      <td>Where the Wild Things Are and Other Maurice Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17766</th>\n",
       "      <td>17767</td>\n",
       "      <td>Fidel Castro: American Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17767</th>\n",
       "      <td>17768</td>\n",
       "      <td>Epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17768</th>\n",
       "      <td>17769</td>\n",
       "      <td>The Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17769</th>\n",
       "      <td>17770</td>\n",
       "      <td>Alien Hunter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17770 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Movie_Id                                               Name\n",
       "0             1                                    Dinosaur Planet\n",
       "1             2                         Isle of Man TT 2004 Review\n",
       "2             3                                          Character\n",
       "3             4                       Paula Abdul's Get Up & Dance\n",
       "4             5                           The Rise and Fall of ECW\n",
       "...         ...                                                ...\n",
       "17765     17766  Where the Wild Things Are and Other Maurice Se...\n",
       "17766     17767                  Fidel Castro: American Experience\n",
       "17767     17768                                              Epoch\n",
       "17768     17769                                        The Company\n",
       "17769     17770                                       Alien Hunter\n",
       "\n",
       "[17770 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie_titles = pd.read_csv(movie_tile_File,\n",
    "                           encoding = \"ISO-8859-1\",\n",
    "                           delimiter= '\\t',\n",
    "                           header = None,\n",
    "                           names = ['Target'])\n",
    "                           # Speicher alle Daten erst in eine Reihe, danach trennt er diese\n",
    "movie_titles[['Movie_Id', 'Year', 'Name']] = movie_titles['Target'].str.split(pat=\",\",n=2, expand=True)   \n",
    "movie_titles= movie_titles.drop(['Target', 'Year'], axis= 1)  \n",
    "Convert_dic= {'Movie_Id': 'int64', 'Name': 'str'}\n",
    "movie_titles = movie_titles.astype(Convert_dic)\n",
    "#movie_titles.astype({'Movie_Id': 'int64', 'Name': 'str'}).dtypes\n",
    "#movie_titles.rename(columns={'Id':'Movie_Id'}, inplace=True)\n",
    "#movie_titles = movie_titles.reset_index(drop=True)\n",
    "display(movie_titles)\n",
    "\n",
    "del Convert_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(data.Cust_Id.unique())\n",
    "num_items = len(data.Movie_Id.unique())\n",
    "print('There are {} unique users and {} unique movies in this data set'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_cnt_tmp = pd.DataFrame(data.groupby('Rating').size(), columns=['count'])\n",
    "df_ratings_cnt_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)\n",
    "print(data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rating frequency\n",
    "df_movies_cnt = pd.DataFrame(data.groupby('Movie_Id').size(), columns=['count'])\n",
    "df_movies_cnt.head()\n",
    "df_movies_cnt['count'].quantile(np.arange(1, 0.6, -0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data\n",
    "popularity_thres = 17700\n",
    "popular_movies = list(set(df_movies_cnt.query('count >= @popularity_thres').index))\n",
    "df_ratings_drop_movies = data[data.Movie_Id.isin(popular_movies)]\n",
    "print('shape of original ratings data: ', data.shape)\n",
    "print('shape of ratings data after dropping unpopular movies: ', df_ratings_drop_movies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of ratings given by every user\n",
    "df_users_cnt = pd.DataFrame(df_ratings_drop_movies.groupby('Cust_Id').size(), columns=['count'])\n",
    "df_users_cnt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_cnt['count'].quantile(np.arange(1, 0.5, -0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data\n",
    "ratings_thres = 500\n",
    "active_users = list(set(df_users_cnt.query('count >= @ratings_thres').index))\n",
    "df_ratings_drop_users = df_ratings_drop_movies[df_ratings_drop_movies.Cust_Id.isin(active_users)]\n",
    "print('shape of original ratings data: ', data.shape)\n",
    "print('shape of ratings data after dropping both unpopular movies and inactive users: ', df_ratings_drop_users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data\n",
    "# Filter sparse movies\n",
    "min_movie_ratings = 1000\n",
    "filter_movies = (df['Movie_Id'].value_counts()>min_movie_ratings)\n",
    "filter_movies = filter_movies[filter_movies].index.tolist()\n",
    "\n",
    "# Filter sparse users\n",
    "min_user_ratings = 200\n",
    "filter_users = (df['Cust_Id'].value_counts()>min_user_ratings)\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "# Actual filtering\n",
    "df_filterd = df[(df['Movie_Id'].isin(filter_movies)) & (df['Cust_Id'].isin(filter_users))]\n",
    "\n",
    "print('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\n",
    "print('Shape User-Ratings filtered:\\t{}'.format(df_filterd.shape))\n",
    "del filter_movies, filter_users, min_movie_ratings, min_user_ratings, data, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie_id_list = df_filterd.Movie_Id.unique().tolist()\n",
    "df_movie_id_list = pd.DataFrame(df_movie_id_list)\n",
    "print(df_movie_id_list.head(4))\n",
    "# Alle movie_Ids die überprüft werden müssen. Alle IDs, werden in ein DataFrame gespeichert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot and create movie-user matrix\n",
    "\n",
    "movie_user_mat = df_filterd.pivot(index='Movie_Id', columns='Cust_Id', values='Rating').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.       Pivot Tabelle, wobei die Movie_IDs Index sind  ( list(movie_user_mat.index.values))\n",
    "## 1.1.     Für jeden Film müssen die nächsten Nachbarn berechnet werden. \n",
    "#  1.2.     Die Iteration der Berechnung soll mit Hilfe des Index in der Tabelle movie_user_mat geschehen. \n",
    "#  2.       Für die nächsten nachbarn soll eine Liste erstellt werden. \n",
    "# 2.1.      Jede Berechnung bzw. die Ergebnisse sollen in eine neue Liste gepackt werden. Spricht alle Iterationen sollen in eine Liste zwischengespeichert werden und am Ende in eine CSV Exportiert werden.\n",
    "\n",
    "\n",
    "#https://github.com/aniketng21/Movie-Recommendation-System-Using-KNN-Algorithm/blob/master/Movie_Recommendation_System.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_index_list = list(movie_user_mat.index.values)\n",
    "# Get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose random movie.\n",
    "#query_index = 8585\n",
    "#query_index = (movie_user_mat.shape[0])\n",
    "# Haiku Tunnel 6899 .95 Precision\n",
    "\n",
    "query_index = np.random.choice(movie_user_mat.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Choosen Movie is: \",movie_user_mat.index[query_index])\n",
    "\n",
    "print(movie_user_mat.index[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_table_matrix = csr_matrix(movie_user_mat.values)\n",
    "model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'auto',n_jobs=-1)\n",
    "model_knn.fit(user_movie_table_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(columns=['Movie_Id', 'R_Movie_Id_1', 'R_Distance_1' , 'R_Movie_Id_2'  , 'R_Distance_2' , 'R_Movie_Id_3'  ,'R_Distance_3','R_Movie_Id_4' ,'R_Distance_4' ,'R_Movie_Id_5' ,'R_Distance_5'])\n",
    "Convert_dic= {'Movie_Id': 'int32', 'R_Movie_Id_1': 'int32','R_Distance_1':'float','R_Movie_Id_2': 'int32','R_Distance_2':'float','R_Movie_Id_3': 'int32','R_Distance_3':'float','R_Movie_Id_4': 'int32','R_Distance_4':'float','R_Movie_Id_5': 'int32','R_Distance_5':'float' }\n",
    "df = df.astype(Convert_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Dataframe List\n",
    "\n",
    "for movie_id in movie_index_list:\n",
    "    #print(movie_id)\n",
    "    movie_id_mat = movie_user_mat.loc[[movie_id]].values.reshape(1,-1)\n",
    "    distances, indices = model_knn.kneighbors(movie_id_mat, n_neighbors = 120)\n",
    "    movie = []\n",
    "    distance = []\n",
    "    \n",
    "\n",
    "    for i in range(0, len(distances.flatten())):\n",
    "        if i != 0:\n",
    "            movie.append(movie_user_mat.index[indices.flatten()[i]])\n",
    "            distance.append(distances.flatten()[i])    \n",
    "\n",
    "    m=pd.Series(movie,name='Movie_Id')\n",
    "    d=pd.Series(distance,name='distance')\n",
    "    recommend = pd.concat([m,d], axis=1)\n",
    "    recommend = recommend.sort_values('distance',ascending=False)\n",
    "\n",
    "\n",
    "    df = df.append({'Movie_Id': movie_id, 'R_Movie_Id_1': recommend['Movie_Id'].iloc[0], 'R_Distance_1':recommend['distance'].iloc[0],\n",
    "        'R_Movie_Id_2': recommend['Movie_Id'].iloc[1], 'R_Distance_2':recommend['distance'].iloc[1],\n",
    "        'R_Movie_Id_3': recommend['Movie_Id'].iloc[2], 'R_Distance_3':recommend['distance'].iloc[2],\n",
    "        'R_Movie_Id_4': recommend['Movie_Id'].iloc[3], 'R_Distance_4':recommend['distance'].iloc[3],\n",
    "        'R_Movie_Id_5': recommend['Movie_Id'].iloc[4], 'R_Distance_5':recommend['distance'].iloc[4]\n",
    "        },ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convert_dic= {'Movie_Id': 'int32', 'R_Movie_Id_1': 'int32','R_Distance_1':'float','R_Movie_Id_2': 'int32','R_Distance_2':'float','R_Movie_Id_3': 'int32','R_Distance_3':'float','R_Movie_Id_4': 'int32','R_Distance_4':'float','R_Movie_Id_5': 'int32','R_Distance_5':'float' }\n",
    "df = df.astype(Convert_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rounded = df.round({'R_Distance_1': 4, 'R_Distance_2':4,'R_Distance_3': 4, 'R_Distance_4':4,'R_Distance_5':4 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Movie_Recommendations.zip',index= 'False', compression= 'gzip')\n",
    "df.to_csv('C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Movie_Recommendations_header.csv',index= False,sep=';',header='True')\n",
    "df_rounded.to_csv('C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Movie_Recommendations_header_rounded.csv',index= False, sep=';',header='True', decimal=',')\n",
    "df.to_parquet('C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Movie_Recommendations_index.zip',index= 'True', compression= 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Movie_Id   R_Movie_Id_1  R_Distance_1       R_Movie_Id_2  \\\n",
      "0                 Character  Bad Education        0.8760  The Piano Teacher   \n",
      "1  The Rise and Fall of ECW   American Pie        0.9313            Be Cool   \n",
      "\n",
      "   R_Distance_2     R_Movie_Id_3  R_Distance_3       R_Movie_Id_4  \\\n",
      "0        0.8760  Kitchen Stories        0.8758  Felicia's Journey   \n",
      "1        0.9313        They Live        0.9311          Rocky III   \n",
      "\n",
      "   R_Distance_4                         R_Movie_Id_5  R_Distance_5  \n",
      "0        0.8757                The Magdalene Sisters        0.8757  \n",
      "1        0.9311  Dave Chappelle: Killin' Them Softly        0.9311  \n"
     ]
    }
   ],
   "source": [
    "print(df_rounded.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rounded.to_csv('C:/Users/jsbreite\\OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/Movie_Recommendations_header_rounded_name.csv',index= False, sep=';',header='True', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Movie_Id  \\\n",
      "0                      Character   \n",
      "1       The Rise and Fall of ECW   \n",
      "2                           Sick   \n",
      "3     What the #$*! Do We Know!?   \n",
      "4                      Screamers   \n",
      "...                          ...   \n",
      "7120                     Gattaca   \n",
      "7121                   Interiors   \n",
      "7122         Shakespeare in Love   \n",
      "7123                       Epoch   \n",
      "7124                 The Company   \n",
      "\n",
      "                                      R_Movie_Id_1  R_Distance_1  \\\n",
      "0                                    Bad Education        0.8760   \n",
      "1                                     American Pie        0.9313   \n",
      "2     The Cook, the Thief, His Wife, and Her Lover        0.9160   \n",
      "3                                    The Godfather        0.8158   \n",
      "4                                       Nightbreed        0.7984   \n",
      "...                                            ...           ...   \n",
      "7120                                 Almost Famous        0.6160   \n",
      "7121                             Dog Day Afternoon        0.8372   \n",
      "7122                              Independence Day        0.5172   \n",
      "7123                                 The Day After        0.8605   \n",
      "7124                                      Election        0.8495   \n",
      "\n",
      "                                       R_Movie_Id_2  R_Distance_2  \\\n",
      "0                                 The Piano Teacher        0.8760   \n",
      "1                                           Be Cool        0.9313   \n",
      "2                               The Virgin Suicides        0.9160   \n",
      "3                Trainspotting: Collector's Edition        0.8148   \n",
      "4                                       Dragonheart        0.7980   \n",
      "...                                             ...           ...   \n",
      "7120  There's Something About Mary: Special Edition        0.6159   \n",
      "7121                                  La Dolce Vita        0.8369   \n",
      "7122                                     Fight Club        0.5166   \n",
      "7123                             The Puppet Masters        0.8602   \n",
      "7124                              Angels in America        0.8492   \n",
      "\n",
      "               R_Movie_Id_3  R_Distance_3  \\\n",
      "0           Kitchen Stories        0.8758   \n",
      "1                 They Live        0.9311   \n",
      "2                    Spider        0.9159   \n",
      "3      The Bourne Supremacy        0.8147   \n",
      "4         Cube 2: Hypercube        0.7977   \n",
      "...                     ...           ...   \n",
      "7120     The Breakfast Club        0.6154   \n",
      "7121        Sophie's Choice        0.8367   \n",
      "7122  Good Morning, Vietnam        0.5165   \n",
      "7123               Timeline        0.8601   \n",
      "7124                Lantana        0.8490   \n",
      "\n",
      "                                 R_Movie_Id_4  R_Distance_4  \\\n",
      "0                           Felicia's Journey        0.8757   \n",
      "1                                   Rocky III        0.9311   \n",
      "2                           Cecil B. Demented        0.9157   \n",
      "3                                  Collateral        0.8145   \n",
      "4          Escape from the Planet of the Apes        0.7977   \n",
      "...                                       ...           ...   \n",
      "7120                Finding Nemo (Widescreen)        0.6152   \n",
      "7121                            The Third Man        0.8363   \n",
      "7122  Harry Potter and the Chamber of Secrets        0.5161   \n",
      "7123                             The Forsaken        0.8601   \n",
      "7124                                  Memento        0.8490   \n",
      "\n",
      "                             R_Movie_Id_5  R_Distance_5  \n",
      "0                   The Magdalene Sisters        0.8757  \n",
      "1     Dave Chappelle: Killin' Them Softly        0.9311  \n",
      "2                The Man Who Wasn't There        0.9156  \n",
      "3                              In America        0.8143  \n",
      "4           Star Trek: The Motion Picture        0.7975  \n",
      "...                                   ...           ...  \n",
      "7120                             Big Fish        0.6143  \n",
      "7121                              Cabaret        0.8357  \n",
      "7122                         Say Anything        0.5158  \n",
      "7123                Village of the Damned        0.8595  \n",
      "7124                           Seabiscuit        0.8488  \n",
      "\n",
      "[7125 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "df_rounded['Movie_Id'] = df_rounded['Movie_Id'].map(movie_titles.set_index('Movie_Id')['Name'])\n",
    "df_rounded['R_Movie_Id_1'] = df_rounded['R_Movie_Id_1'].map(movie_titles.set_index('Movie_Id')['Name'])\n",
    "df_rounded['R_Movie_Id_2'] = df_rounded['R_Movie_Id_2'].map(movie_titles.set_index('Movie_Id')['Name'])\n",
    "df_rounded['R_Movie_Id_3'] = df_rounded['R_Movie_Id_3'].map(movie_titles.set_index('Movie_Id')['Name'])\n",
    "df_rounded['R_Movie_Id_4'] = df_rounded['R_Movie_Id_4'].map(movie_titles.set_index('Movie_Id')['Name'])\n",
    "df_rounded['R_Movie_Id_5'] = df_rounded['R_Movie_Id_5'].map(movie_titles.set_index('Movie_Id')['Name'])\n",
    "print(df_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not Good Code\n",
    "#\n",
    "#\n",
    "movie_list  = {}\n",
    "for movie_id in movie_index_list[:5]:\n",
    "    #print(movie_id)\n",
    "    movie_id_mat = movie_user_mat.loc[[movie_id]].values.reshape(1,-1)\n",
    "    distances, indices = model_knn.kneighbors(movie_id_mat, n_neighbors = 60)\n",
    "    movie_list[movie_id] = []\n",
    "    movie = []\n",
    "    distance = []\n",
    "    \n",
    "\n",
    "    for i in range(0, len(distances.flatten())):\n",
    "        if i != 0:\n",
    "            movie.append(movie_user_mat.index[indices.flatten()[i]])\n",
    "            distance.append(distances.flatten()[i])    \n",
    "\n",
    "    m=pd.Series(movie,name='Movie_Id')\n",
    "    d=pd.Series(distance,name='distance')\n",
    "    recommend = pd.concat([m,d], axis=1)\n",
    "    recommend = recommend.sort_values('distance',ascending=False)\n",
    "\n",
    "    print('Recommendations for {0}:\\n'.format(movie_id))\n",
    "    #test_list.append(movie_id, recommend['Movie_Id'].iloc[i], recommend['distance'].iloc[i],recommend['Movie_Id'].iloc[1+i], recommend['distance'].iloc[1+i])\n",
    "   \n",
    "    df = df.append({'Movie_Id': movie_id, 'R_Movie_Id_1': recommend['Movie_Id'].iloc[0], 'R_Distance_1':recommend['distance'].iloc[0],\n",
    "        'R_Movie_Id_2': recommend['Movie_Id'].iloc[1], 'R_Distance_2':recommend['distance'].iloc[1],\n",
    "        'R_Movie_Id_3': recommend['Movie_Id'].iloc[2], 'R_Distance_3':recommend['distance'].iloc[2],\n",
    "        'R_Movie_Id_4': recommend['Movie_Id'].iloc[3], 'R_Distance_4':recommend['distance'].iloc[3],\n",
    "        'R_Movie_Id_5': recommend['Movie_Id'].iloc[4], 'R_Distance_5':recommend['distance'].iloc[4]\n",
    "        },ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(0,5):\n",
    "        #df= df.append({'Movie_Id': movie_id})\n",
    "        movie_list[movie_id].append({'Movie_Id': recommend['Movie_Id'].iloc[i], 'distance': recommend['distance'].iloc[i]})\n",
    "\n",
    "        #df = pf.dataframe({'Movie_ID': [movie_id, recommend['Movie_Id'].iloc[i]]})\n",
    "        \n",
    "        print('{0}: {1}, with distance of {2}'.format(i, recommend[\"Movie_Id\"].iloc[i], recommend[\"distance\"].iloc[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(movie_list)\n",
    "recommendation_list = pd.DataFrame(movie_list).transpose()\n",
    "print(recommendation_list.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_user_mat.iloc[query_index,:].values.reshape(1,-1))\n",
    "\n",
    "print(movie_user_mat.index[[1406]])\n",
    "print(movie_user_mat.iloc[[1406]].values.reshape(1,-1))\n",
    "print(movie_user_mat.shape)\n",
    "print(query_index)\n",
    "\n",
    "#Heute aebnd verstehen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(movie_user_mat.index[3,:].values.reshape(1,-1))\n",
    "print(\"Choosen Movie is: \",movie_user_mat.index[query_index])\n",
    "print(movie_user_mat.iloc[1406,:].values.reshape(1,-1))\n",
    "\n",
    "print(movie_user_mat.iloc[query_index,:].values.reshape(1,-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration aufbauen\n",
    "distances, indices = model_knn.kneighbors(movie_user_mat.iloc[query_index,:].values.reshape(1,-1), n_neighbors = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = model_knn.kneighbors(test_jannis, n_neighbors = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Muss durch jeden Film ausgeführt werden Iteration ausgeführt werden.\n",
    "distances, indices = model_knn.kneighbors(movie_user_mat, n_neighbors = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in Movie_index_list:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list = {}\n",
    "\n",
    "\n",
    "for name_movie, values in movie_user_mat.iteritems():\n",
    "    movie_list[name_movie] = []\n",
    "    movie = []\n",
    "    distance = []\n",
    "\n",
    "    for i in range(0, len(distances.flatten())):\n",
    "        if i != 0:\n",
    "            movie.append(movie_user_mat.index[indices.flatten()[i]])\n",
    "            distance.append(distances.flatten()[i])    \n",
    "\n",
    "    m=pd.Series(movie,name='Movie_Id')\n",
    "    d=pd.Series(distance,name='distance')\n",
    "    recommend = pd.concat([m,d], axis=1)\n",
    "    recommend = recommend.sort_values('distance',ascending=False)\n",
    "\n",
    "    print('Recommendations for {0}:\\n'.format(movie_user_mat.index[query_index]))\n",
    "    \n",
    "\n",
    "    for i in range(0,5):\n",
    "        movie_list[name_movie].append({\"Movie_Id\": recommend[\"Movie_Id\"].iloc[i], \"distance\": recommend[\"distance\"].iloc[i]})\n",
    "        print('{0}: {1}, with distance of {2}'.format(i, recommend[\"Movie_Id\"].iloc[i], recommend[\"distance\"].iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Backup\n",
    "movie = []\n",
    "distance = []\n",
    "\n",
    "for i in range(0, len(distances.flatten())):\n",
    "    if i != 0:\n",
    "        movie.append(movie_user_mat.index[indices.flatten()[i]])\n",
    "        distance.append(distances.flatten()[i])    \n",
    "\n",
    "m=pd.Series(movie,name='Movie_Id')\n",
    "d=pd.Series(distance,name='distance')\n",
    "recommend = pd.concat([m,d], axis=1)\n",
    "recommend = recommend.sort_values('distance',ascending=False)\n",
    "\n",
    "print('Recommendations for {0}:\\n'.format(movie_user_mat.index[query_index]))\n",
    "for i in range(0,recommend.shape[0]):\n",
    "    print('{0}: {1}, with distance of {2}'.format(i, recommend[\"Movie_Id\"].iloc[i], recommend[\"distance\"].iloc[i]))\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grundgedanke... Es gibt eine Matrix mit 17700 Filmen (Movie_IDs), jeder Film soll mit einem Title im DataFrame movie_titles verbunden werden. \n",
    "# Jeder Film soll einmal durch das Modell \"K-NN\" laufen und in einem neuem Dataframe gespeichert werden. Sodass ein neuer DataFrame entsteht, wo in der Erste Spalte der Film steht und in den weiteren 5 Spalten die Empfehlung + Distance\n",
    "\n",
    "# zu jeden Film sollen 5 weitere Filme vorgeschlagen werden.! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kann vernachlässigt werden....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot and create movie-user matrix\n",
    "#del data, \n",
    "movie_user_mat = df_filterd.pivot(index='Movie_Id', columns='Cust_Id', values='Rating').fillna(0)\n",
    "\n",
    "# create mapper from movie title to index\n",
    "movie_to_idx = {\n",
    "   movie: i for i, movie in \n",
    "    enumerate(list(movie_titles.set_index('Movie_Id').loc[movie_user_mat.index].Name))\n",
    "}\n",
    "# transform matrix to scipy sparse matrix\n",
    "movie_user_mat_sparse = csr_matrix(movie_user_mat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_matching(mapper, fav_movie, verbose=True):\n",
    "    #https://www.kaggle.com/code/ibtesama/getting-started-with-a-movie-recommendation-system\n",
    "    #https://www.kaggle.com/code/razor08/knn-based-collaborative-filtering?scriptVersionId=81850169  Wo kommmt der Code her\n",
    "    \"\"\"\n",
    "    return the closest match via fuzzy ratio. If no match found, return None\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    mapper: dict, map movie title name to index of the movie in data\n",
    "\n",
    "    fav_movie: str, name of user input movie\n",
    "    \n",
    "    verbose: bool, print log if True\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    index of the closest match\n",
    "    \"\"\"\n",
    "    match_tuple = []\n",
    "    # get match\n",
    "    for title, idx in mapper.items():\n",
    "        ratio = fuzz.ratio(title.lower(), fav_movie.lower())\n",
    "        if ratio >= 60:\n",
    "            match_tuple.append((title, idx, ratio))\n",
    "    # sort\n",
    "    match_tuple = sorted(match_tuple, key=lambda x: x[2])[::-1]\n",
    "    if not match_tuple:\n",
    "        print('Oops! No match is found')\n",
    "        return\n",
    "    if verbose:\n",
    "        print('Found possible matches in our database: {0}\\n'.format([x[0] for x in match_tuple]))\n",
    "    return match_tuple[0][1]\n",
    "\n",
    "\n",
    "\n",
    "def make_recommendation(model_knn, data, mapper, fav_movie, n_recommendations):\n",
    "    # fit\n",
    "    model_knn.fit(data)\n",
    "    # get input movie index\n",
    "    print('You have input movie:', fav_movie)\n",
    "    idx = fuzzy_matching(mapper, fav_movie, verbose=True)\n",
    "    # inference\n",
    "    print('Recommendation system start to make inference')\n",
    "    print('......\\n')\n",
    "    distances, indices = model_knn.kneighbors(data[idx], n_neighbors=n_recommendations+1)\n",
    "    # get list of raw idx of recommendations\n",
    "    raw_recommends = \\\n",
    "        sorted(list(zip(indices.squeeze().tolist(), distances.squeeze().tolist())), key=lambda x: x[1])[:0:-1]\n",
    "    # get reverse mapper\n",
    "    reverse_mapper = {v: k for k, v in mapper.items()}\n",
    "    # print recommendations\n",
    "    print('Recommendations for {}:'.format(fav_movie))\n",
    "    for i, (idx, dist) in enumerate(raw_recommends):\n",
    "        print('{0}: {1}, with distance of {2}'.format(i+1, reverse_mapper[idx], dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=120, n_jobs=-1)\n",
    "# fit\n",
    "model_knn.fit(movie_user_mat_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_favorite = 'Haiku Tunnel'\n",
    "\n",
    "make_recommendation(\n",
    "    model_knn=model_knn,\n",
    "    data=movie_user_mat_sparse,\n",
    "    fav_movie=my_favorite,\n",
    "    mapper=movie_to_idx,\n",
    "    n_recommendations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Läuft nicht!!!\n",
    "# https://datascience.stackexchange.com/questions/52704/how-to-save-a-knn-model\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "\"\"\"\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=70, n_jobs=-1)\n",
    "# fit\n",
    "model_knn.fit(movie_user_mat_sparse)\n",
    "\"\"\"\n",
    "knn = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=70, n_jobs=-1)\n",
    "knn.fit(movie_user_mat_sparse)\n",
    "\n",
    "# Its important to use binary mode \n",
    "knnpickle_file = 'C:/Users/jsbreite/OneDrive - Jannis Breitenstein IT/Hochschule_Studium/5_Semester/Programmierprojekt/Netflix_Daten/KNN-Model.sav'\n",
    "knnPickle = open('knnpickle_file', 'wb') \n",
    "\n",
    "# source, destination \n",
    "pickle.dump(knn, knnPickle)  \n",
    "\n",
    "# close the file\n",
    "knnPickle.close()\n",
    "                \n",
    "      \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open('knnpickle_file', 'rb'))\n",
    "result = loaded_model.predict(movie_user_mat_sparse) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1acf06c8fd8bc80800f08a72a7dc06ca6ff72dd3d390f63a44d70f4da57fac27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
